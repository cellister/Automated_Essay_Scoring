{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQ2yZrRKLWgv"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions\n",
        "!pip install --upgrade keras-nlp\n",
        "!pip install --upgrade keras\n",
        "#!pip install --upgrade tensorflow\n",
        "!pip install tensorflow==2.8.0\n",
        "!pip install transformers==4.18.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU5PDUs_m9GQ",
        "outputId": "41b4e96b-cd68-40b1-dfd9-f94e30e9fc12"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n",
            "Collecting keras-nlp\n",
            "  Downloading keras_nlp-0.12.1-py3-none-any.whl (570 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m570.5/570.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-core (from keras-nlp)\n",
            "  Downloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (24.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (2024.5.15)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (13.7.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.1.8)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.2.5)\n",
            "Collecting tensorflow-text (from keras-nlp)\n",
            "  Downloading tensorflow_text-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-nlp) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-nlp) (4.66.4)\n",
            "Collecting namex (from keras-core->keras-nlp)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras-nlp) (3.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-nlp) (2.16.1)\n",
            "Collecting tensorflow<2.17,>=2.16.1 (from tensorflow-text->keras-nlp)\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-nlp) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (0.2.0)\n",
            "Collecting h5py (from keras-core->keras-nlp)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (4.12.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (1.64.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras>=3.0.0 (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp)\n",
            "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (0.37.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-nlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-nlp) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-nlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-nlp) (2024.6.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (0.43.0)\n",
            "Collecting optree (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras-nlp) (2.1.5)\n",
            "Installing collected packages: namex, optree, ml-dtypes, h5py, tensorboard, keras-core, keras, tensorflow, tensorflow-text, keras-nlp\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h5py-3.11.0 keras-3.3.3 keras-core-0.1.7 keras-nlp-0.12.1 ml-dtypes-0.3.2 namex-0.0.8 optree-0.11.0 tensorboard-2.16.2 tensorflow-2.16.1 tensorflow-text-2.16.1\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.3.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras) (4.12.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Collecting tensorflow==2.8.0\n",
            "  Downloading tensorflow-2.8.0-cp310-cp310-manylinux2010_x86_64.whl (497.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.6/497.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (24.3.25)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.11.0)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow==2.8.0)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (18.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (4.12.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.14.1)\n",
            "Collecting tensorboard<2.9,>=2.8 (from tensorflow==2.8.0)\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tf-estimator-nightly==2.8.0.dev2021122109 (from tensorflow==2.8.0)\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.5/462.5 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0 (from tensorflow==2.8.0)\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.0) (1.64.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.31.0)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.9,>=2.8->tensorflow==2.8.0)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.2)\n",
            "Installing collected packages: tf-estimator-nightly, tensorboard-plugin-wit, keras, tensorboard-data-server, keras-preprocessing, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.3.3\n",
            "    Uninstalling keras-3.3.3:\n",
            "      Successfully uninstalled keras-3.3.3\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.16.2\n",
            "    Uninstalling tensorboard-2.16.2:\n",
            "      Successfully uninstalled tensorboard-2.16.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.16.1\n",
            "    Uninstalling tensorflow-2.16.1:\n",
            "      Successfully uninstalled tensorflow-2.16.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-text 2.16.1 requires tensorflow<2.17,>=2.16.1; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.8.0 which is incompatible.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 keras-2.8.0 keras-preprocessing-1.1.2 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n",
            "Collecting transformers==4.18.0\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (2.31.0)\n",
            "Collecting sacremoses (from transformers==4.18.0)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.18.0)\n",
            "  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.18.0) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.18.0) (2024.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18.0) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.18.0) (1.4.2)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.2\n",
            "    Uninstalling transformers-4.41.2:\n",
            "      Successfully uninstalled transformers-4.41.2\n",
            "Successfully installed sacremoses-0.1.1 tokenizers-0.12.1 transformers-4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Print Python version\n",
        "print(\"Python version:\")\n",
        "print(sys.version)\n",
        "print()\n",
        "\n",
        "# Function to get the name of the virtual environment\n",
        "def get_environment_name():\n",
        "    venv = os.getenv('VIRTUAL_ENV')\n",
        "    if venv:\n",
        "        return os.path.basename(venv)\n",
        "    else:\n",
        "        return \"No virtual environment detected\"\n",
        "\n",
        "# Print environment name\n",
        "print(\"Environment name:\")\n",
        "print(get_environment_name())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-gq_IVmsYf9",
        "outputId": "8b5fd3a1-e090-4bff-b51e-4200672ee953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version:\n",
            "3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "\n",
            "Environment name:\n",
            "No virtual environment detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# TensorFlow and Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Transformers and Keras NLP\n",
        "import transformers\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "import keras_nlp\n",
        "import keras.backend as K\n",
        "\n",
        "\n",
        "# Other utilities\n",
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import contractions\n",
        "import inflect\n",
        "import re\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "# Initialize the inflect engine\n",
        "p = inflect.engine()\n",
        "\n",
        "# Set colormap\n",
        "cmap = mpl.cm.get_cmap('plasma')\n",
        "\n",
        "# Ensure reproducibility\n",
        "np.random.seed(0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PSSyznvroYjX",
        "outputId": "4d73350c-de01-46f1-96c7-87f4a61d6fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-3c8f0646d36b>:44: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
            "  cmap = mpl.cm.get_cmap('plasma')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"transformers version: {transformers.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1sDfX-ZpDpG",
        "outputId": "68c6e501-bb23-48e0-c254-8f181bb4de6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.8.0\n",
            "transformers version: 4.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is setting an environment variable KERAS_BACKEND to either \"jax\", \"tensorflow\", or \"torch\". This variable specifies the backend engine that Keras, a high-level neural networks API, will use for computation.\n",
        "\n",
        "By setting it to \"jax\", it indicates that Keras should use the JAX (Just Another eXperimental) backend for computation. JAX is a numerical computing library developed by Google, known for its automatic differentiation and ability to accelerate numerical code on CPUs, GPUs, and TPUs.\n",
        "\n",
        "Alternatively, setting it to \"tensorflow\" indicates the use of TensorFlow as the backend, while setting it to \"torch\" indicates the use of PyTorch as the backend. These are other popular deep learning frameworks that can be used with Keras as the frontend API for building and training neural networks."
      ],
      "metadata": {
        "id": "ob1g5bhnDrUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data/EDA"
      ],
      "metadata": {
        "id": "TdMfF1Ps_1u1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFjesmz89Ug8",
        "outputId": "a8f9b8a5-527c-4d27-bf17-4ab4f6f4ef41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1gF8_HqWLWgy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "2d790ccf-d96f-4460-9aa3-aba230e6b652"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2c34995342e1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0messay_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sample_data/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Randomly sample 2000 essays from the dataset, due to RAM limitations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0messay_df_sampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0messay_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "essay_df = pd.read_csv('sample_data/train.csv')\n",
        "\n",
        "# Randomly sample 2000 essays from the dataset, due to RAM limitations\n",
        "essay_df_sampled = essay_df.sample(n=2000, random_state=42)\n",
        "\n",
        "essay_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "examine the data in Numbers to get a sense of the punctuation or text traits that may need to be addressed in preprocessing."
      ],
      "metadata": {
        "id": "BUyLbwxyeGNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def min_max_normalization(score):\n",
        "    return (score - 1) / (6-1)\n"
      ],
      "metadata": {
        "id": "pLLIuFYiZ9Av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preproccessing"
      ],
      "metadata": {
        "id": "OxOhRjtgACi2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pVVOnjyLWgy"
      },
      "outputs": [],
      "source": [
        "def contains_numeric(token):\n",
        "  return any(char.isdigit() for char in token)\n",
        "\n",
        "\n",
        "def convert_numbers_to_words(token):\n",
        "  if contains_numeric(token):\n",
        "    # Remove any punctuation from the token before conversion\n",
        "    # Keeps alphanumeric, whitespace, and \".\"s, remove anything else\n",
        "    token = re.sub(r'[^\\w\\s.]', '', token)\n",
        "\n",
        "    wordString = p.number_to_words(token)\n",
        "\n",
        "    wordString = wordString.replace(\"-\", \" \")\n",
        "\n",
        "    # Tokenize the wordString\n",
        "    tokens = word_tokenize(wordString)\n",
        "\n",
        "    return tokens # Return the flat list of tokens instead of a list of lists\n",
        "  else:\n",
        "    return [token] # Return the token as a list\n",
        "\n",
        "# Takes in a raw essay - just a long string\n",
        "# Outputs a cleaned up list of tokens\n",
        "\n",
        "def preprocess(rawEssay):\n",
        "  # Step 1: replace hypens with spaces\n",
        "  rawEssay = rawEssay.replace(\"-\", \" \")\n",
        "\n",
        "  # Step 2: replace % with the word percent\n",
        "  rawEssay = rawEssay.replace(\"%\", \"percent\")\n",
        "\n",
        "  # Put any other future single character manipulations here\n",
        "\n",
        "  # Step 3: expand contractions ex: I'm -> I am\n",
        "  essayExpanded = contractions.fix(rawEssay)\n",
        "\n",
        "  # Step 4: take the big long string and turn it into tokens (individual strings)\n",
        "  tokens = word_tokenize(essayExpanded) # just splitting on spaces\n",
        "\n",
        "  # Step 5: convert the numberic tokens to one or more word tokens\n",
        "  # ex: 10% -> ['ten', 'percent'] or 1.00 -> ['one', 'point', 'zero', 'zero']\n",
        "  # use a new array to preserve the order of the tokens\n",
        "  processedTokens = []\n",
        "\n",
        "  # leaves non-numeric tokens alone\n",
        "  for token in tokens:\n",
        "    processedTokens.extend(convert_numbers_to_words(token))\n",
        "\n",
        "  # Step 6: remove non-alphabet tokens and lowercase everything\n",
        "  essayTokens = [word.lower() for word in processedTokens if word.isalpha()]\n",
        "\n",
        "  # Step 7: remove stop words (common words like 'the', 'and', etc.)\n",
        "  stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "  essayTokensClean = [word for word in essayTokens if word not in stop_words]\n",
        "\n",
        "  return essayTokensClean"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the essays\n",
        "essay_df['preprocessed'] = essay_df['full_text'].apply(preprocess)\n",
        "essay_df['preprocessed_str'] = essay_df['preprocessed'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Normalize scores\n",
        "essay_df['normalized_score'] = essay_df.apply(lambda row: min_max_normalization(row['score']), axis=1)\n",
        "\n",
        "essay_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "qhtOg901aPZ5",
        "outputId": "22f1ab2c-9a3f-4e04-93d3-8e7f24f4a816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     essay_id                                          full_text  score  \\\n",
              "0     000d118  Many people have car where they live. The thin...      3   \n",
              "1     000fe60  I am a scientist at NASA that is discussing th...      3   \n",
              "2     001ab80  People always wish they had the same technolog...      4   \n",
              "3     001bdc0  We all heard about Venus, the planet without a...      4   \n",
              "4     002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3   \n",
              "...       ...                                                ...    ...   \n",
              "1995  1e860bc  Driveless cars is not a smart idea. Its a posi...      2   \n",
              "1996  1e88fb2  I honestly think that we don't need driverless...      2   \n",
              "1997  1e8c487  Dont you think that having driveless cars will...      4   \n",
              "1998  1e8cded  No! The Face found on Mars is not formed by al...      2   \n",
              "1999  1e8d2f8  It would be unfair to disregard this opportuni...      3   \n",
              "\n",
              "                                           preprocessed  \\\n",
              "0     [many, people, car, live, thing, know, use, ca...   \n",
              "1     [scientist, nasa, discussing, face, mars, expl...   \n",
              "2     [people, always, wish, technology, seen, movie...   \n",
              "3     [heard, venus, planet, without, almost, oxygen...   \n",
              "4     [dear, state, senator, letter, argue, favor, k...   \n",
              "...                                                 ...   \n",
              "1995  [driveless, cars, smart, idea, posiablity, cal...   \n",
              "1996  [honestly, think, need, driverless, cars, reas...   \n",
              "1997  [think, driveless, cars, cause, many, problems...   \n",
              "1998  [face, found, mars, formed, aliens, face, foun...   \n",
              "1999  [would, unfair, disregard, opportunity, civili...   \n",
              "\n",
              "                                       preprocessed_str  normalized_score  \n",
              "0     many people car live thing know use car alot t...               0.4  \n",
              "1     scientist nasa discussing face mars explaining...               0.4  \n",
              "2     people always wish technology seen movies best...               0.6  \n",
              "3     heard venus planet without almost oxygen earth...               0.6  \n",
              "4     dear state senator letter argue favor keeping ...               0.4  \n",
              "...                                                 ...               ...  \n",
              "1995  driveless cars smart idea posiablity called sm...               0.2  \n",
              "1996  honestly think need driverless cars reasoning ...               0.2  \n",
              "1997  think driveless cars cause many problems insta...               0.6  \n",
              "1998  face found mars formed aliens face found mars ...               0.2  \n",
              "1999  would unfair disregard opportunity civilians r...               0.4  \n",
              "\n",
              "[2000 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7770912d-21fb-49b3-8751-f2ce50526a29\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>score</th>\n",
              "      <th>preprocessed</th>\n",
              "      <th>preprocessed_str</th>\n",
              "      <th>normalized_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000d118</td>\n",
              "      <td>Many people have car where they live. The thin...</td>\n",
              "      <td>3</td>\n",
              "      <td>[many, people, car, live, thing, know, use, ca...</td>\n",
              "      <td>many people car live thing know use car alot t...</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000fe60</td>\n",
              "      <td>I am a scientist at NASA that is discussing th...</td>\n",
              "      <td>3</td>\n",
              "      <td>[scientist, nasa, discussing, face, mars, expl...</td>\n",
              "      <td>scientist nasa discussing face mars explaining...</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ab80</td>\n",
              "      <td>People always wish they had the same technolog...</td>\n",
              "      <td>4</td>\n",
              "      <td>[people, always, wish, technology, seen, movie...</td>\n",
              "      <td>people always wish technology seen movies best...</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001bdc0</td>\n",
              "      <td>We all heard about Venus, the planet without a...</td>\n",
              "      <td>4</td>\n",
              "      <td>[heard, venus, planet, without, almost, oxygen...</td>\n",
              "      <td>heard venus planet without almost oxygen earth...</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>002ba53</td>\n",
              "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
              "      <td>3</td>\n",
              "      <td>[dear, state, senator, letter, argue, favor, k...</td>\n",
              "      <td>dear state senator letter argue favor keeping ...</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>1e860bc</td>\n",
              "      <td>Driveless cars is not a smart idea. Its a posi...</td>\n",
              "      <td>2</td>\n",
              "      <td>[driveless, cars, smart, idea, posiablity, cal...</td>\n",
              "      <td>driveless cars smart idea posiablity called sm...</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>1e88fb2</td>\n",
              "      <td>I honestly think that we don't need driverless...</td>\n",
              "      <td>2</td>\n",
              "      <td>[honestly, think, need, driverless, cars, reas...</td>\n",
              "      <td>honestly think need driverless cars reasoning ...</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>1e8c487</td>\n",
              "      <td>Dont you think that having driveless cars will...</td>\n",
              "      <td>4</td>\n",
              "      <td>[think, driveless, cars, cause, many, problems...</td>\n",
              "      <td>think driveless cars cause many problems insta...</td>\n",
              "      <td>0.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>1e8cded</td>\n",
              "      <td>No! The Face found on Mars is not formed by al...</td>\n",
              "      <td>2</td>\n",
              "      <td>[face, found, mars, formed, aliens, face, foun...</td>\n",
              "      <td>face found mars formed aliens face found mars ...</td>\n",
              "      <td>0.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>1e8d2f8</td>\n",
              "      <td>It would be unfair to disregard this opportuni...</td>\n",
              "      <td>3</td>\n",
              "      <td>[would, unfair, disregard, opportunity, civili...</td>\n",
              "      <td>would unfair disregard opportunity civilians r...</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7770912d-21fb-49b3-8751-f2ce50526a29')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7770912d-21fb-49b3-8751-f2ce50526a29 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7770912d-21fb-49b3-8751-f2ce50526a29');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-67f12548-5c26-4d04-a0a3-6b466b9c33f3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-67f12548-5c26-4d04-a0a3-6b466b9c33f3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-67f12548-5c26-4d04-a0a3-6b466b9c33f3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_dda31e17-be97-4724-ba49-39aa4713488d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('essay_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dda31e17-be97-4724-ba49-39aa4713488d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('essay_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "essay_df",
              "summary": "{\n  \"name\": \"essay_df\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"essay_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"1c8b117\",\n          \"0608fab\",\n          \"14cfa29\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"Many people have different opinions about what happens on the planet Mars. During a recent discovery many people had the idea that the face on mars was created by aliens. Scientists had a different theory. Scientists believed that the face was formed by something more believable. Aliens was not one of those.\\n\\nOn May 24th NASA's Viking 1 spacecraft was on Mars. The spacecraft was going about it's regular mission until it noticed something interesting. The text states, \\\"..when it spotted the shadowy likenss of a human face.\\\" The text states, \\\"A few days later NASA unveiled the image for all to see.\\\" Once NASA revealed the images for the world to see, many of them claimed it was from aliens. Scientists had to quickly do their research to clear up false accusations. The text states, \\\"Thousands of anxious web surfers were waiting when the image first appeared on a JPL web site, revealing...a natural landform. There was no alien monument after all.\\\" Once NASA cleared it up that it wasn't an alien monument they quickly found out what the face was. The text states, \\\"What the picture actually shows is the Martian equivalent of a butte or mesa---landforms common around the American West. NASA was able to put an end to the false accusations, and also support their conclusion with nautral landforms.\\n\\nWhile many people do have different opinions about certain things, sometimes those opinions can chhange. By being able to provide people with evidence as to why something is the way it is can steer thier opinion in another direction. NASA had many followers who felt that the face on Mars was caused by aliens, but NASA was quick to provide them with correct imformation on the formation of the face.\",\n          \"In the passage \\\"Car-Free Cities\\\" Have many advantages, but i feel that the main advantage is that it is good for the planet and to lower air pollution and aslo the movement is actually working.\\n\\nHelping out the planet and staying green in some way is a good thing because it helps our planet look better not only that it makes it look better but it also makes us humans and the planet Earth healthier for example the air pollution can be lowered by driving cars less,instead od driving your own car you could take the bus,walk, or ride like in the text it says\\n\\n\\\"Its's a good opportunity to take away stress and lower air pollution,\\\" said businessman Carlos Arturo Plaza as he rode a two-seat bicycle with his wife.\\\"\\n\\nI like this piece of evidence because it tels more on how being green can not only help the planet but alo tell how it can help human kind, because it helps you understand not only it can lower pollution but it can also lower your stress, but if you choice not to go along with the movement you shouldn't have to pay a fine of 5$ because to me it seems like that would be taking away a persons rights yes i get it \\\"\\n\\nThe goal is to promote altnative transportatin and reduce smog\\\"\\n\\nbut a person should not be force to do so.\\n\\nAnother advantage could be that the movement is working\\n\\n\\\"President Obama's ambitious goals to curb the United States' greenhouse gas emissions, unveiled last week, will get a fortuitous assist from an incipient shift in American behavior: recent studies suggest that Americans are buying fewer cars, driving less and getting fewer licenses as each year goes by.\\n\\nI like this piece of evidence from \\\"Source 4: The End of Car Culture\\\" By Elisabeth Rosenthal because it states what the president is doing to try and make our planet better, but not only that it also gives factual information by telling about fewer cars are being broughten each year and also fewer licenses are also being gotten\\n\\nAll in all this passage have many good advantages to help persuade people to start driving less and helping out our planet, One it is good for our planet because no one wants to live in a dirty place, Two it will help lower the bad air pollution, and Lastly is that the movement is working anyways so why not try and help out and drive a little less?       \\u00a0       \\u00a0    \",\n          \"Dear Florida senator,\\n\\nI strongly agree of keeping the Electoral College for the use of the congress' approval for the newly President of 2016. The Electoral College has a lengthy process, but can come in good use of determining the new President. Citizens vote for the electors and the electors decide who's best for the country. Even though, there are claims about the Electoral College not being fair for the people, I still defend it because it has it's good factors, like Run-off Elections,the requirement that a presidential candidate to have trans-regional appeal for the people, and the resoring weight of the eletoral number by population.\\n\\nAs so you know, the Electoral College is a process of the selction of the electors, then the gathering of electors to vote for the president and vice president. Finally, the electoral votes by the Congress. When the electors pick the president, they look at their background, such as, what school they attend, what they studied, where they were born, etc. They pick someone they trust to do the job. When there is a Run-off Election, the House Of Representatives picks the president. I personally think this is a good thing because they picked the person who would do best in the job by gathering everyone's vote to decide it. Because no country could have two presidents with two vice presidents. Some may say it's unjustice or not fair because the House Of Representatives decides the whole election. There is also the fact that when determining the winner, they both look at the popular votes and the electoral votes, and they see who got the most electoral votes and they win the election.\\n\\nThe Electoral College\\u00a0 puts it simple, because they choose someone with a region where they most likely get the most electoral votes. For example, Romney was in the South region, and he knows he wouldn't have to do much there because of that was where he was currently from. Now lets compare that to someone that was in the area around North Dakota. He would most likely not win that many votes since it's only three electoral numbers. So the Electoral College gives a chance for the president they chose to win because of where they used to be located in order to get the most popular and electoral votes.\\n\\nThe Electoral College restores and reduces some of the weight of the electoral by its population. Smalls states aren't widely noticed by the president because they feel like they should concentrated in the big states because of there electoral votes. Still, small states tend to make it easier for them because they look at if the state was either Republican or Democrac during the past years and they take note of that. They know they'll win in those states, even though they are small numbers, every inch of it counts to help them win the title of President.\\n\\nTherefore, Mister Sentor, I agree in keeping the Electoral Vote because of it's reasonable factors that can help the president win. Popular vote doesn't tell anything because the people would know nothing about the president or what he accomplished. It should be kept because it has been used for many years now and has been useful for every president to win.\\n\\nTo Whom I Name,\\n\\nV.       \\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0       \\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0    \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3,\n          4,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed_str\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"many people different opinions happens planet mars recent discovery many people idea face mars created aliens scientists different theory scientists believed face formed something believable aliens one may twenty fourth nasa viking one spacecraft mars spacecraft going regular mission noticed something interesting text states spotted shadowy likenss human face text states days later nasa unveiled image see nasa revealed images world see many claimed aliens scientists quickly research clear false accusations text states thousands anxious web surfers waiting image first appeared jpl web site revealing natural landform alien monument nasa cleared alien monument quickly found face text states picture actually shows martian equivalent butte mesa landforms common around american west nasa able put end false accusations also support conclusion nautral landforms many people different opinions certain things sometimes opinions chhange able provide people evidence something way steer thier opinion another direction nasa many followers felt face mars caused aliens nasa quick provide correct imformation formation face\",\n          \"passage car free cities many advantages feel main advantage good planet lower air pollution aslo movement actually working helping planet staying green way good thing helps planet look better makes look better also makes us humans planet earth healthier example air pollution lowered driving cars less instead od driving car could take bus walk ride like text says good opportunity take away stress lower air pollution said businessman carlos arturo plaza rode two seat bicycle wife like piece evidence tels green help planet alo tell help human kind helps understand lower pollution also lower stress choice go along movement pay fine five seems like would taking away persons rights yes get goal promote altnative transportatin reduce smog person force another advantage could movement working president obama ambitious goals curb united states greenhouse gas emissions unveiled last week get fortuitous assist incipient shift american behavior recent studies suggest americans buying fewer cars driving less getting fewer licenses year goes like piece evidence source four end car culture elisabeth rosenthal states president try make planet better also gives factual information telling fewer cars broughten year also fewer licenses also gotten passage many good advantages help persuade people start driving less helping planet one good planet one wants live dirty place two help lower bad air pollution lastly movement working anyways try help drive little less\",\n          \"dear florida senator strongly agree keeping electoral college use congress approval newly president two thousand sixteen electoral college lengthy process come good use determining new president citizens vote electors electors decide best country even though claims electoral college fair people still defend good factors like run elections requirement presidential candidate trans regional appeal people resoring weight eletoral number population know electoral college process selction electors gathering electors vote president vice president finally electoral votes congress electors pick president look background school attend studied born etc pick someone trust job run election house representatives picks president personally think good thing picked person would best job gathering everyone vote decide country could two presidents two vice presidents may say unjustice fair house representatives decides whole election also fact determining winner look popular votes electoral votes see got electoral votes win election electoral college puts simple choose someone region likely get electoral votes example romney south region knows would much currently let us compare someone area around north dakota would likely win many votes since three electoral numbers electoral college gives chance president chose win used located order get popular electoral votes electoral college restores reduces weight electoral population smalls states widely noticed president feel like concentrated big states electoral votes still small states tend make easier look state either republican democrac past years take note know win states even though small numbers every inch counts help win title president therefore mister sentor agree keeping electoral vote reasonable factors help president win popular vote tell anything people would know nothing president accomplished kept used many years useful every president win name v\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"normalized_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20480315467805432,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.4,\n          0.6,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here a Bert Tokenizer is used. The Bert (Bidirectional Encoder Representations from Transformers) is a pre-trained transformer-based model for natural language understanding tasks, trained on large amounts of text data.\n",
        "\n",
        "Transformer-based models (like BERT), can capture intricate nuances in language usage, context, and semantics. BERT excels in understanding the relationships between different parts of the text and can provide nuanced assessments aligned with the criteria of the rubric. Additionally, the bidirectional nature allows BERT to consider the entire context of the essay when making scoring decisions."
      ],
      "metadata": {
        "id": "MZS-Y8aObMo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "def bert_vectorizer(text):\n",
        "    inputs = tokenizer(text, return_tensors='tf', truncation=True, padding=True)\n",
        "    outputs = bert_model(inputs)\n",
        "    return tf.reduce_mean(outputs.last_hidden_state, axis=1).numpy().squeeze()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254,
          "referenced_widgets": [
            "4812187f46a240f7be791e7a6a525ad3",
            "6ad85d6d62d246bb8781df496b708d56",
            "e14c42796dcf4862af5b918a241acfe7",
            "22bd7fac00e14f258be333c0a79a4625",
            "644c6adafbf7480aa703ad260c716a63",
            "0d049a356417406d9b29543940fa3ec7",
            "c0fb7c7a1bab4503b4a3a6f41031abd4",
            "21aff9822ac3460ca4b5a80ce2293d4f",
            "82a6dced54664ad680d0fa1e1a907553",
            "f0efe287dd0a4fb3a71bc8bc7d710f42",
            "d664b0dc951f4771b27cb462208ee1c2",
            "7e4a671c756d44ce80828c9cd201d6f4",
            "b8fa4ab3f0ac47fd875f64e0004304ec",
            "24bf2ce5220c468f84b67fbbec6ab496",
            "574a418cf24c42c499993e1597e1817c",
            "a1a8f5fb8fc74a378b780279e83665f6",
            "a610cd40eb4d43aba9b94c743a12d747",
            "c654a1cef1064ce5bb92930f23e0df2e",
            "12dcd54d4bc7444b91a591e6b0c03412",
            "f0cfb6f20d824d0c970d32b23e2e1e47",
            "40af5014e1d44dd6919cb3ee9fa1305c",
            "b8b350dcc3fb4d6188111310be6486e5",
            "6b7dca9d59044bae86bbfc6ad0d93dcd",
            "8ca3fc4d447e4a3fa9bae61ff4c73af2",
            "6210ee27b8da4837b38b50e04c5af293",
            "c3356e0fb94e424aa56929a50a0961f2",
            "3775dde66594459684248a327f97d127",
            "0d91fb1c289d41409e57c7bf0ac303f4",
            "9fcda4b703994d7ab3130932ed9bc52d",
            "204c8bfb58a3427bbd6834fc461c3394",
            "410ff4e839b04dcd9555162987d8b562",
            "05e70f1aeea24fd99b3bfc0d16c1f95b",
            "833ed02498804692bf3b7bb55db959be",
            "206da8bed7bd4a6b98c253ce654ce97e",
            "06cfbd28a0c1424c86105b18945ec2d8",
            "abbec0e5cdc1458fa94b45561f5b85e1",
            "99d22c3afdbc4356b349ab228a348589",
            "a3bb7390e39b4f3bb8cf5b175eaba42a",
            "a37322b047e2479ea8872211c8f179bb",
            "841186a9207349d1b7def548f43fa7bf",
            "8f049b6dfbee433a993e04622a5e7ce0",
            "12a248a826ee408a8f4467be7a0dfa24",
            "69c678a1a6044c5d8e5efc31569cd366",
            "d9d9863ec08b43fbb64b18020e64115c"
          ]
        },
        "id": "3GL5zfnIaesS",
        "outputId": "ffac0b94-e8ba-4cbc-e92a-2c058f71b327"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4812187f46a240f7be791e7a6a525ad3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e4a671c756d44ce80828c9cd201d6f4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b7dca9d59044bae86bbfc6ad0d93dcd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/511M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "206da8bed7bd4a6b98c253ce654ce97e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# just the first 2000 rows from the data: due to size of RAM needed\n",
        "#this is where the shared and BERT data frame split\n",
        "essay_df_BERT = essay_df.iloc[:2000]\n",
        "\n",
        "# Vectorize!\n",
        "essay_df_BERT['bert_embeddings'] = essay_df_BERT['preprocessed_str'].apply(bert_vectorizer)\n"
      ],
      "metadata": {
        "id": "R4xP1oXwj54y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "essay_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "EJq9vAc10aH6",
        "outputId": "e16403c6-76b6-4005-88bd-6e1858c618e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     essay_id                                          full_text  score  \\\n",
              "0     000d118  Many people have car where they live. The thin...      3   \n",
              "1     000fe60  I am a scientist at NASA that is discussing th...      3   \n",
              "2     001ab80  People always wish they had the same technolog...      4   \n",
              "3     001bdc0  We all heard about Venus, the planet without a...      4   \n",
              "4     002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3   \n",
              "...       ...                                                ...    ...   \n",
              "1995  1e860bc  Driveless cars is not a smart idea. Its a posi...      2   \n",
              "1996  1e88fb2  I honestly think that we don't need driverless...      2   \n",
              "1997  1e8c487  Dont you think that having driveless cars will...      4   \n",
              "1998  1e8cded  No! The Face found on Mars is not formed by al...      2   \n",
              "1999  1e8d2f8  It would be unfair to disregard this opportuni...      3   \n",
              "\n",
              "                                           preprocessed  \\\n",
              "0     [many, people, car, live, thing, know, use, ca...   \n",
              "1     [scientist, nasa, discussing, face, mars, expl...   \n",
              "2     [people, always, wish, technology, seen, movie...   \n",
              "3     [heard, venus, planet, without, almost, oxygen...   \n",
              "4     [dear, state, senator, letter, argue, favor, k...   \n",
              "...                                                 ...   \n",
              "1995  [driveless, cars, smart, idea, posiablity, cal...   \n",
              "1996  [honestly, think, need, driverless, cars, reas...   \n",
              "1997  [think, driveless, cars, cause, many, problems...   \n",
              "1998  [face, found, mars, formed, aliens, face, foun...   \n",
              "1999  [would, unfair, disregard, opportunity, civili...   \n",
              "\n",
              "                                       preprocessed_str  normalized_score  \\\n",
              "0     many people car live thing know use car alot t...               0.4   \n",
              "1     scientist nasa discussing face mars explaining...               0.4   \n",
              "2     people always wish technology seen movies best...               0.6   \n",
              "3     heard venus planet without almost oxygen earth...               0.6   \n",
              "4     dear state senator letter argue favor keeping ...               0.4   \n",
              "...                                                 ...               ...   \n",
              "1995  driveless cars smart idea posiablity called sm...               0.2   \n",
              "1996  honestly think need driverless cars reasoning ...               0.2   \n",
              "1997  think driveless cars cause many problems insta...               0.6   \n",
              "1998  face found mars formed aliens face found mars ...               0.2   \n",
              "1999  would unfair disregard opportunity civilians r...               0.4   \n",
              "\n",
              "                                        bert_embeddings  \n",
              "0     [-0.19236295, 0.08298609, 0.6363683, 0.0106769...  \n",
              "1     [-0.092922196, 0.3568951, 0.61868125, -0.05716...  \n",
              "2     [-0.21923193, 0.1289193, 0.74725866, 0.0657115...  \n",
              "3     [-0.40675154, 0.46219572, 0.63158137, -0.08010...  \n",
              "4     [-0.2286655, 0.15533702, 0.47521192, 0.1232781...  \n",
              "...                                                 ...  \n",
              "1995  [-0.20641454, 0.17281477, 0.67518735, 0.262342...  \n",
              "1996  [0.091167934, 0.19328213, 0.5347322, 0.1609850...  \n",
              "1997  [-0.08717857, 0.13759647, 0.7566045, 0.0769002...  \n",
              "1998  [-0.14090557, 0.32685202, 0.54560494, -0.08251...  \n",
              "1999  [-0.12539671, -0.030961491, 0.5598796, -0.0137...  \n",
              "\n",
              "[2000 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4a5e0e2-0de2-4280-9d8e-a342e9a6133c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>score</th>\n",
              "      <th>preprocessed</th>\n",
              "      <th>preprocessed_str</th>\n",
              "      <th>normalized_score</th>\n",
              "      <th>bert_embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000d118</td>\n",
              "      <td>Many people have car where they live. The thin...</td>\n",
              "      <td>3</td>\n",
              "      <td>[many, people, car, live, thing, know, use, ca...</td>\n",
              "      <td>many people car live thing know use car alot t...</td>\n",
              "      <td>0.4</td>\n",
              "      <td>[-0.19236295, 0.08298609, 0.6363683, 0.0106769...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000fe60</td>\n",
              "      <td>I am a scientist at NASA that is discussing th...</td>\n",
              "      <td>3</td>\n",
              "      <td>[scientist, nasa, discussing, face, mars, expl...</td>\n",
              "      <td>scientist nasa discussing face mars explaining...</td>\n",
              "      <td>0.4</td>\n",
              "      <td>[-0.092922196, 0.3568951, 0.61868125, -0.05716...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ab80</td>\n",
              "      <td>People always wish they had the same technolog...</td>\n",
              "      <td>4</td>\n",
              "      <td>[people, always, wish, technology, seen, movie...</td>\n",
              "      <td>people always wish technology seen movies best...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>[-0.21923193, 0.1289193, 0.74725866, 0.0657115...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001bdc0</td>\n",
              "      <td>We all heard about Venus, the planet without a...</td>\n",
              "      <td>4</td>\n",
              "      <td>[heard, venus, planet, without, almost, oxygen...</td>\n",
              "      <td>heard venus planet without almost oxygen earth...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>[-0.40675154, 0.46219572, 0.63158137, -0.08010...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>002ba53</td>\n",
              "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
              "      <td>3</td>\n",
              "      <td>[dear, state, senator, letter, argue, favor, k...</td>\n",
              "      <td>dear state senator letter argue favor keeping ...</td>\n",
              "      <td>0.4</td>\n",
              "      <td>[-0.2286655, 0.15533702, 0.47521192, 0.1232781...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>1e860bc</td>\n",
              "      <td>Driveless cars is not a smart idea. Its a posi...</td>\n",
              "      <td>2</td>\n",
              "      <td>[driveless, cars, smart, idea, posiablity, cal...</td>\n",
              "      <td>driveless cars smart idea posiablity called sm...</td>\n",
              "      <td>0.2</td>\n",
              "      <td>[-0.20641454, 0.17281477, 0.67518735, 0.262342...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>1e88fb2</td>\n",
              "      <td>I honestly think that we don't need driverless...</td>\n",
              "      <td>2</td>\n",
              "      <td>[honestly, think, need, driverless, cars, reas...</td>\n",
              "      <td>honestly think need driverless cars reasoning ...</td>\n",
              "      <td>0.2</td>\n",
              "      <td>[0.091167934, 0.19328213, 0.5347322, 0.1609850...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>1e8c487</td>\n",
              "      <td>Dont you think that having driveless cars will...</td>\n",
              "      <td>4</td>\n",
              "      <td>[think, driveless, cars, cause, many, problems...</td>\n",
              "      <td>think driveless cars cause many problems insta...</td>\n",
              "      <td>0.6</td>\n",
              "      <td>[-0.08717857, 0.13759647, 0.7566045, 0.0769002...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>1e8cded</td>\n",
              "      <td>No! The Face found on Mars is not formed by al...</td>\n",
              "      <td>2</td>\n",
              "      <td>[face, found, mars, formed, aliens, face, foun...</td>\n",
              "      <td>face found mars formed aliens face found mars ...</td>\n",
              "      <td>0.2</td>\n",
              "      <td>[-0.14090557, 0.32685202, 0.54560494, -0.08251...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>1e8d2f8</td>\n",
              "      <td>It would be unfair to disregard this opportuni...</td>\n",
              "      <td>3</td>\n",
              "      <td>[would, unfair, disregard, opportunity, civili...</td>\n",
              "      <td>would unfair disregard opportunity civilians r...</td>\n",
              "      <td>0.4</td>\n",
              "      <td>[-0.12539671, -0.030961491, 0.5598796, -0.0137...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4a5e0e2-0de2-4280-9d8e-a342e9a6133c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a4a5e0e2-0de2-4280-9d8e-a342e9a6133c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a4a5e0e2-0de2-4280-9d8e-a342e9a6133c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fd0db3c4-17eb-47cf-88a4-7a3135cfe4ea\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd0db3c4-17eb-47cf-88a4-7a3135cfe4ea')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fd0db3c4-17eb-47cf-88a4-7a3135cfe4ea button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_75d5e7fb-1f0e-4fff-9420-78ff8750fe84\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('essay_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_75d5e7fb-1f0e-4fff-9420-78ff8750fe84 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('essay_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "essay_df",
              "summary": "{\n  \"name\": \"essay_df\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"essay_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"1c8b117\",\n          \"0608fab\",\n          \"14cfa29\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"Many people have different opinions about what happens on the planet Mars. During a recent discovery many people had the idea that the face on mars was created by aliens. Scientists had a different theory. Scientists believed that the face was formed by something more believable. Aliens was not one of those.\\n\\nOn May 24th NASA's Viking 1 spacecraft was on Mars. The spacecraft was going about it's regular mission until it noticed something interesting. The text states, \\\"..when it spotted the shadowy likenss of a human face.\\\" The text states, \\\"A few days later NASA unveiled the image for all to see.\\\" Once NASA revealed the images for the world to see, many of them claimed it was from aliens. Scientists had to quickly do their research to clear up false accusations. The text states, \\\"Thousands of anxious web surfers were waiting when the image first appeared on a JPL web site, revealing...a natural landform. There was no alien monument after all.\\\" Once NASA cleared it up that it wasn't an alien monument they quickly found out what the face was. The text states, \\\"What the picture actually shows is the Martian equivalent of a butte or mesa---landforms common around the American West. NASA was able to put an end to the false accusations, and also support their conclusion with nautral landforms.\\n\\nWhile many people do have different opinions about certain things, sometimes those opinions can chhange. By being able to provide people with evidence as to why something is the way it is can steer thier opinion in another direction. NASA had many followers who felt that the face on Mars was caused by aliens, but NASA was quick to provide them with correct imformation on the formation of the face.\",\n          \"In the passage \\\"Car-Free Cities\\\" Have many advantages, but i feel that the main advantage is that it is good for the planet and to lower air pollution and aslo the movement is actually working.\\n\\nHelping out the planet and staying green in some way is a good thing because it helps our planet look better not only that it makes it look better but it also makes us humans and the planet Earth healthier for example the air pollution can be lowered by driving cars less,instead od driving your own car you could take the bus,walk, or ride like in the text it says\\n\\n\\\"Its's a good opportunity to take away stress and lower air pollution,\\\" said businessman Carlos Arturo Plaza as he rode a two-seat bicycle with his wife.\\\"\\n\\nI like this piece of evidence because it tels more on how being green can not only help the planet but alo tell how it can help human kind, because it helps you understand not only it can lower pollution but it can also lower your stress, but if you choice not to go along with the movement you shouldn't have to pay a fine of 5$ because to me it seems like that would be taking away a persons rights yes i get it \\\"\\n\\nThe goal is to promote altnative transportatin and reduce smog\\\"\\n\\nbut a person should not be force to do so.\\n\\nAnother advantage could be that the movement is working\\n\\n\\\"President Obama's ambitious goals to curb the United States' greenhouse gas emissions, unveiled last week, will get a fortuitous assist from an incipient shift in American behavior: recent studies suggest that Americans are buying fewer cars, driving less and getting fewer licenses as each year goes by.\\n\\nI like this piece of evidence from \\\"Source 4: The End of Car Culture\\\" By Elisabeth Rosenthal because it states what the president is doing to try and make our planet better, but not only that it also gives factual information by telling about fewer cars are being broughten each year and also fewer licenses are also being gotten\\n\\nAll in all this passage have many good advantages to help persuade people to start driving less and helping out our planet, One it is good for our planet because no one wants to live in a dirty place, Two it will help lower the bad air pollution, and Lastly is that the movement is working anyways so why not try and help out and drive a little less?       \\u00a0       \\u00a0    \",\n          \"Dear Florida senator,\\n\\nI strongly agree of keeping the Electoral College for the use of the congress' approval for the newly President of 2016. The Electoral College has a lengthy process, but can come in good use of determining the new President. Citizens vote for the electors and the electors decide who's best for the country. Even though, there are claims about the Electoral College not being fair for the people, I still defend it because it has it's good factors, like Run-off Elections,the requirement that a presidential candidate to have trans-regional appeal for the people, and the resoring weight of the eletoral number by population.\\n\\nAs so you know, the Electoral College is a process of the selction of the electors, then the gathering of electors to vote for the president and vice president. Finally, the electoral votes by the Congress. When the electors pick the president, they look at their background, such as, what school they attend, what they studied, where they were born, etc. They pick someone they trust to do the job. When there is a Run-off Election, the House Of Representatives picks the president. I personally think this is a good thing because they picked the person who would do best in the job by gathering everyone's vote to decide it. Because no country could have two presidents with two vice presidents. Some may say it's unjustice or not fair because the House Of Representatives decides the whole election. There is also the fact that when determining the winner, they both look at the popular votes and the electoral votes, and they see who got the most electoral votes and they win the election.\\n\\nThe Electoral College\\u00a0 puts it simple, because they choose someone with a region where they most likely get the most electoral votes. For example, Romney was in the South region, and he knows he wouldn't have to do much there because of that was where he was currently from. Now lets compare that to someone that was in the area around North Dakota. He would most likely not win that many votes since it's only three electoral numbers. So the Electoral College gives a chance for the president they chose to win because of where they used to be located in order to get the most popular and electoral votes.\\n\\nThe Electoral College restores and reduces some of the weight of the electoral by its population. Smalls states aren't widely noticed by the president because they feel like they should concentrated in the big states because of there electoral votes. Still, small states tend to make it easier for them because they look at if the state was either Republican or Democrac during the past years and they take note of that. They know they'll win in those states, even though they are small numbers, every inch of it counts to help them win the title of President.\\n\\nTherefore, Mister Sentor, I agree in keeping the Electoral Vote because of it's reasonable factors that can help the president win. Popular vote doesn't tell anything because the people would know nothing about the president or what he accomplished. It should be kept because it has been used for many years now and has been useful for every president to win.\\n\\nTo Whom I Name,\\n\\nV.       \\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0       \\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0\\u00a0    \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 6,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          3,\n          4,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"preprocessed_str\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          \"many people different opinions happens planet mars recent discovery many people idea face mars created aliens scientists different theory scientists believed face formed something believable aliens one may twenty fourth nasa viking one spacecraft mars spacecraft going regular mission noticed something interesting text states spotted shadowy likenss human face text states days later nasa unveiled image see nasa revealed images world see many claimed aliens scientists quickly research clear false accusations text states thousands anxious web surfers waiting image first appeared jpl web site revealing natural landform alien monument nasa cleared alien monument quickly found face text states picture actually shows martian equivalent butte mesa landforms common around american west nasa able put end false accusations also support conclusion nautral landforms many people different opinions certain things sometimes opinions chhange able provide people evidence something way steer thier opinion another direction nasa many followers felt face mars caused aliens nasa quick provide correct imformation formation face\",\n          \"passage car free cities many advantages feel main advantage good planet lower air pollution aslo movement actually working helping planet staying green way good thing helps planet look better makes look better also makes us humans planet earth healthier example air pollution lowered driving cars less instead od driving car could take bus walk ride like text says good opportunity take away stress lower air pollution said businessman carlos arturo plaza rode two seat bicycle wife like piece evidence tels green help planet alo tell help human kind helps understand lower pollution also lower stress choice go along movement pay fine five seems like would taking away persons rights yes get goal promote altnative transportatin reduce smog person force another advantage could movement working president obama ambitious goals curb united states greenhouse gas emissions unveiled last week get fortuitous assist incipient shift american behavior recent studies suggest americans buying fewer cars driving less getting fewer licenses year goes like piece evidence source four end car culture elisabeth rosenthal states president try make planet better also gives factual information telling fewer cars broughten year also fewer licenses also gotten passage many good advantages help persuade people start driving less helping planet one good planet one wants live dirty place two help lower bad air pollution lastly movement working anyways try help drive little less\",\n          \"dear florida senator strongly agree keeping electoral college use congress approval newly president two thousand sixteen electoral college lengthy process come good use determining new president citizens vote electors electors decide best country even though claims electoral college fair people still defend good factors like run elections requirement presidential candidate trans regional appeal people resoring weight eletoral number population know electoral college process selction electors gathering electors vote president vice president finally electoral votes congress electors pick president look background school attend studied born etc pick someone trust job run election house representatives picks president personally think good thing picked person would best job gathering everyone vote decide country could two presidents two vice presidents may say unjustice fair house representatives decides whole election also fact determining winner look popular votes electoral votes see got electoral votes win election electoral college puts simple choose someone region likely get electoral votes example romney south region knows would much currently let us compare someone area around north dakota would likely win many votes since three electoral numbers electoral college gives chance president chose win used located order get popular electoral votes electoral college restores reduces weight electoral population smalls states widely noticed president feel like concentrated big states electoral votes still small states tend make easier look state either republican democrac past years take note know win states even though small numbers every inch counts help win title president therefore mister sentor agree keeping electoral vote reasonable factors help president win popular vote tell anything people would know nothing president accomplished kept used many years useful every president win name v\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"normalized_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.20480315467805432,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.4,\n          0.6,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bert_embeddings\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "__UXs7PrGER-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "info check: for the first essay, did the Bert imbedding work? did it do what we expected it to? Let's check the difference between the preprocessing and the bert embedding data. It's a high dimenstional vector (768 coordinates) ... is the output what we expect to see? The output dimensions of BERT are 768-dimensional."
      ],
      "metadata": {
        "id": "dy7o3Tkd0oQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the full content of the 'bert_embeddings' column for the first row\n",
        "bert_embeddings = essay_df_BERT.loc[0, 'bert_embeddings']\n",
        "print(bert_embeddings)\n",
        "print(len(bert_embeddings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bOlxExP304Rn",
        "outputId": "3c253568-f00d-4143-e1cb-4bcf179dac2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1.92362949e-01  8.29860866e-02  6.36368275e-01  1.06769074e-02\n",
            "  3.74182642e-01 -3.45125288e-01 -3.92479077e-02  3.41112077e-01\n",
            " -6.50211647e-02 -4.70099241e-01  1.76800549e-01 -2.31049374e-01\n",
            "  5.53200245e-02  3.07868302e-01 -5.13604701e-01  1.97924703e-01\n",
            "  2.55806595e-01  6.60879910e-02 -2.67492950e-01  1.40256286e-01\n",
            "  4.20323372e-01 -1.06729269e-01  3.25917721e-01  1.49777114e-01\n",
            "  2.33164251e-01 -2.66135156e-01  9.52418670e-02 -1.54365540e-01\n",
            " -1.88152995e-02 -8.73150080e-02  3.39345247e-01  1.48254603e-01\n",
            " -1.40494242e-01 -1.93352684e-01  9.95634049e-02 -1.90355644e-01\n",
            " -3.24222296e-02 -7.38745555e-02  6.77717552e-02  2.16156736e-01\n",
            " -2.56184042e-01 -3.89201999e-01 -3.02773386e-01  4.86161411e-02\n",
            " -3.49825740e-01 -6.72156364e-02 -5.30487113e-03  6.48419112e-02\n",
            "  4.74616401e-02 -2.74416715e-01 -1.58299312e-01 -1.19155843e-03\n",
            " -7.21136779e-02  1.24721296e-01  2.14930009e-02  3.63495052e-01\n",
            " -2.89259627e-02 -2.53422171e-01 -2.89860547e-01 -1.74504042e-01\n",
            "  2.88238794e-01 -1.11479625e-01  2.70544499e-01  2.66226325e-02\n",
            "  2.89879084e-01 -2.11487323e-01 -7.31984377e-02  2.28800058e-01\n",
            " -3.91588926e-01 -3.07315797e-01 -3.94354284e-01 -2.16819078e-01\n",
            " -1.41590416e-01  1.13227919e-01 -8.18659142e-02 -1.30588621e-01\n",
            " -5.55231012e-02  2.77776897e-01  3.45541984e-01 -2.78091609e-01\n",
            " -3.08849186e-01  1.40895903e-01 -4.90372449e-01  2.23493859e-01\n",
            "  8.63156244e-02  6.47420138e-02  1.88918605e-01  8.28067437e-02\n",
            " -4.91016299e-01  3.09275389e-01  2.41695449e-01 -3.07056248e-01\n",
            "  1.44054085e-01 -1.26328647e-01  1.68020721e-03  5.00913374e-02\n",
            " -1.82489026e-02  1.02304295e-01 -9.26803704e-03  6.59817815e-01\n",
            " -4.71304767e-02 -1.30662084e-01  2.65374869e-01  2.01583371e-01\n",
            "  1.09407410e-01 -1.34671569e-01 -2.15718523e-02  4.12454784e-01\n",
            "  1.50083691e-01  2.39151582e-01  4.26136196e-01 -1.03687972e-01\n",
            " -1.33843526e-01 -1.19525678e-01 -2.35225379e-01  3.84636410e-02\n",
            "  1.42912224e-01  4.21215333e-02  2.31833071e-01  8.67782086e-02\n",
            " -1.56891704e-01 -4.61351648e-02  1.51597038e-01  6.80208266e-01\n",
            " -3.05961389e-02  1.70671344e-01 -3.80250305e-01  4.62855399e-01\n",
            " -1.02603458e-01  4.42481674e-02  1.54385909e-01  1.19049124e-01\n",
            " -2.78306782e-01 -1.99992195e-01 -8.11120868e-03  2.49448761e-01\n",
            "  1.68393075e-01 -6.04477450e-02 -2.08892301e-01  1.39424829e-02\n",
            "  3.04542899e-01  7.91854039e-02  3.33893716e-01  1.08308539e-01\n",
            " -2.00403538e-02 -2.99436017e-03 -2.15447783e-01 -2.24229142e-01\n",
            "  8.51170998e-03  5.65312862e-01 -2.88015194e-02  1.92989066e-01\n",
            "  6.28174320e-02  1.53403193e-01 -6.83837235e-02  9.70585346e-02\n",
            " -3.66337866e-01 -5.80019355e-02  6.07352797e-03 -1.20652467e-01\n",
            "  4.49250564e-02 -1.62199214e-02 -4.73660789e-03 -1.07755847e-01\n",
            "  2.33635828e-01 -2.67167717e-01 -1.10634483e-01  1.67614505e-01\n",
            " -3.06046993e-01  1.05051585e-02 -7.29304403e-02 -1.71990357e-02\n",
            "  6.55982673e-01 -2.00606257e-01  2.03655958e-01  3.86124589e-02\n",
            "  3.43095154e-01 -3.47221404e-01  5.71294874e-02  6.15511894e-01\n",
            " -3.56553495e-01  4.51585978e-01 -2.50849098e-01  2.32652068e-01\n",
            "  1.39981480e-02 -8.84149522e-02  3.70577216e-01  1.31089315e-01\n",
            "  2.54756302e-01 -1.10338807e-01 -9.19706449e-02 -1.60169095e-01\n",
            " -4.58860323e-02  6.80887550e-02  5.34309208e-01 -1.64935708e-01\n",
            "  2.16371775e-01  1.79744869e-01 -1.42235160e-01 -1.99091900e-02\n",
            "  2.39677243e-02  1.16853349e-01  5.09244084e-01  2.46113956e-01\n",
            " -3.19587380e-01  4.23120968e-02  2.16342315e-01 -5.18790036e-02\n",
            "  1.50061011e-01  1.85156077e-01 -2.91035343e-02  3.54653537e-01\n",
            "  3.28836709e-01  2.34202862e-01 -1.83156684e-01 -3.79432291e-01\n",
            "  1.95714995e-01  2.35627353e-01  3.78461838e-01  3.76997180e-02\n",
            " -2.24717204e-02  2.49340788e-01 -2.83349544e-01  4.38025266e-01\n",
            " -3.20546776e-01  5.36571801e-01  3.95062566e-01 -6.52505219e-01\n",
            " -9.56132915e-03  1.94612592e-01 -5.58240265e-02 -3.02609265e-01\n",
            "  4.69866633e-01 -3.66425753e-01 -8.14174339e-02  1.27985150e-01\n",
            "  8.38205218e-02 -9.21876952e-02  5.24836741e-02 -3.64164054e-01\n",
            " -2.89253324e-01  2.28843391e-01  1.79617107e-01 -7.76920095e-02\n",
            " -5.55928089e-02 -3.39486748e-01 -1.11238882e-01 -1.65542483e-01\n",
            " -1.63460746e-01 -5.63498020e-01 -4.42466676e-01  1.94250792e-01\n",
            "  1.72815382e-01 -3.91118973e-01  3.16186179e-03 -3.69215727e-01\n",
            "  6.73337355e-02 -3.60306203e-01 -1.44967651e-02  2.05129031e-02\n",
            "  5.52415289e-02  2.49146447e-01 -3.69720273e-02 -5.14689786e-03\n",
            " -4.61776316e-01 -4.13894385e-01 -2.23388821e-01  2.52620935e-01\n",
            "  1.73946083e-01  7.37215579e-02  1.68213636e-01  1.75434515e-01\n",
            "  5.03183343e-02  4.27147716e-01 -8.08895975e-02  1.64466798e-01\n",
            "  3.70868921e-01  6.09455645e-01  9.99131650e-02 -1.58069283e-01\n",
            "  1.18076615e-01  5.16291916e-01  3.62127066e-01 -2.08575338e-01\n",
            "  8.79659206e-02 -1.90152824e-01 -6.74285814e-02  3.04255128e-01\n",
            " -4.61601885e-03 -2.44440347e-01  1.73310582e-02  3.92258316e-02\n",
            " -1.16795458e-01  1.22551480e-02  4.16441947e-01  1.17493115e-01\n",
            " -2.44129539e-01 -9.69816297e-02  2.12895602e-01 -2.46052146e-01\n",
            " -3.44464421e-01  2.94082463e-01 -5.98036796e-02  1.02208637e-01\n",
            "  2.47867838e-01 -1.32370740e-01 -2.68733263e-01 -1.59923345e-01\n",
            " -4.41846752e+00 -9.73830670e-02 -6.20400198e-02 -1.89863369e-01\n",
            "  2.87466079e-01 -3.83196145e-01  1.80637345e-01 -8.58704075e-02\n",
            " -4.32074100e-01  2.99569309e-01  4.36360501e-02 -1.10712595e-01\n",
            " -6.74975058e-03  4.80363905e-01  2.63660550e-01  1.46342278e-01\n",
            " -2.37987518e-01 -1.23788305e-01 -3.23481679e-01  3.39388371e-01\n",
            " -3.04600578e-02 -4.29947138e-01  2.64423966e-01  5.02946414e-02\n",
            "  2.77870387e-01  4.48318990e-03 -1.47063211e-01  2.35841960e-01\n",
            " -4.32133406e-01 -1.74794659e-01  5.43552041e-01  6.24910966e-02\n",
            "  3.45493779e-02  1.00486241e-01  1.29820123e-01 -7.94714242e-02\n",
            "  2.47339960e-02 -2.83869624e-01 -3.93812567e-01 -3.91441405e-01\n",
            " -2.29503736e-01 -7.23432541e-01 -7.04543814e-02  1.51184708e-01\n",
            "  4.64279920e-01 -1.03124827e-02 -3.02553177e-01 -9.29610804e-02\n",
            "  1.17343485e-01  2.08440572e-01  2.23095998e-01  2.00227425e-01\n",
            " -3.22377652e-01 -9.93439481e-02 -1.68429799e-02 -3.43759507e-02\n",
            "  4.80965883e-01  8.12008798e-01 -6.32115752e-02 -2.60400444e-01\n",
            " -2.16825530e-01  7.88267031e-02 -5.45224547e-01 -1.46848693e-01\n",
            " -8.84188563e-02 -7.10433424e-02 -4.62541342e-01 -9.94364917e-02\n",
            " -6.81474432e-02  1.50718510e-01 -3.38583350e-01  3.39262784e-01\n",
            " -1.91849276e-01 -2.44868368e-01 -2.08246306e-01  5.42572178e-02\n",
            "  1.69335175e-02 -4.21524160e-02  3.07046305e-02  5.27192712e-01\n",
            " -4.21416052e-02 -1.27675369e-01 -2.64030369e-03 -3.82116884e-02\n",
            " -1.69127017e-01 -4.82429802e-01  6.62011877e-02 -2.71905750e-01\n",
            " -1.44167989e-01 -4.07297462e-01  5.05563498e-01 -1.30735010e-01\n",
            "  2.85954088e-01 -1.99798301e-01  5.23356140e-01  1.45283490e-01\n",
            "  1.63165763e-01 -3.46396446e-01  3.76839697e-01 -5.03264666e-01\n",
            "  4.22401100e-01  7.52574578e-02  3.59893322e-01 -4.39211667e-01\n",
            "  3.05458456e-01 -2.07693338e-01 -9.01426747e-02  3.57957244e-01\n",
            " -2.15574726e-03  1.00550704e-01  8.07204098e-02 -2.09060460e-01\n",
            "  4.09564912e-01 -5.59347093e-01 -2.74125516e-01 -1.63193747e-01\n",
            "  3.04877996e-01  3.98933500e-01 -7.66006485e-02 -2.13473260e-01\n",
            "  4.13283296e-02  2.56787539e-01 -2.28165865e-01 -7.04674363e-01\n",
            " -5.46028793e-01  3.40654701e-01 -6.06932461e-01  1.73638925e-01\n",
            " -1.68059185e-01  3.52055997e-01 -2.68115163e-01  1.40729062e-02\n",
            "  6.76373020e-02 -1.13066010e-01  3.94150496e-01 -1.31605476e-01\n",
            " -1.66487604e-01 -6.85476124e-01 -1.05893448e-01  4.83781248e-02\n",
            "  6.79092947e-03 -2.19545081e-01  1.11372426e-01 -1.20672986e-01\n",
            "  4.53872383e-02  3.04470628e-01 -1.38299227e-01 -1.17364340e-01\n",
            " -2.97034323e-01 -1.18381895e-01 -4.99989241e-01 -5.78343451e-01\n",
            " -1.70705214e-01  4.21735011e-02 -1.06941931e-01  4.59145345e-02\n",
            "  2.82132328e-01 -9.82337594e-02 -1.14200644e-01 -6.00977182e-01\n",
            "  3.10216029e-03 -6.01699129e-02 -2.26727854e-02  9.10469443e-02\n",
            " -3.48610878e-02  3.85649830e-01  8.91685188e-02 -3.15491617e-01\n",
            "  5.51485345e-02  3.30546089e-02  2.24418640e-02 -2.75288314e-01\n",
            " -5.38632333e-01 -5.86407818e-02  4.45451625e-02  5.13055027e-01\n",
            "  2.59873182e-01 -2.35642940e-01 -3.14810902e-01  1.99915513e-01\n",
            " -1.09128244e-01  2.21277654e-01 -3.64570588e-01 -1.47521228e-01\n",
            "  4.35267985e-01  1.67352892e-02  1.74575642e-01 -2.20729902e-01\n",
            "  3.82171012e-03 -4.73306999e-02 -9.62586794e-03  4.17402565e-01\n",
            " -1.68790102e-01  4.05100822e-01  1.70015823e-02 -9.96268634e-03\n",
            "  4.70945954e-01  4.08372879e-02 -5.02588116e-02  7.90288597e-02\n",
            "  1.18329622e-01 -2.61264980e-01 -2.88705565e-02  3.09872944e-02\n",
            "  3.72889549e-01 -3.65474671e-01  1.38798833e-01  2.39117905e-01\n",
            "  1.64348334e-01  1.43533871e-01 -6.40512645e-01 -4.60684866e-01\n",
            " -2.85378426e-01  5.66989370e-02  2.63252705e-01 -3.90567183e-01\n",
            "  1.55785963e-01 -1.39351144e-01 -6.07283056e-01  1.18086495e-01\n",
            " -1.14272431e-01 -1.06184840e-01 -3.60543698e-01 -2.86896050e-01\n",
            " -1.98184967e-01 -3.27030048e-02  1.30842000e-01 -2.67959684e-01\n",
            " -2.24599931e-02 -1.46105021e-01  1.39990598e-01 -6.89203024e-01\n",
            "  1.12148099e-01  1.41672149e-01 -1.52534857e-01  2.30665848e-01\n",
            "  1.28328777e-03 -5.64935982e-01  6.65207654e-02  3.44653353e-02\n",
            " -3.52843143e-02  5.20855263e-02 -2.01222628e-01 -7.04845428e-01\n",
            "  1.98527604e-01  3.93821120e-01 -1.10038862e-01  4.58034784e-01\n",
            "  2.60439957e-03  3.92238766e-01 -2.10003823e-01  9.47230384e-02\n",
            " -1.17883226e-02 -3.60488027e-01  1.64683089e-01 -5.53550959e-01\n",
            " -5.62590897e-01  2.14944378e-01 -2.54772276e-01 -2.05637328e-03\n",
            " -2.54398316e-01 -1.17887676e-01  7.88821280e-02 -1.71216041e-01\n",
            "  1.03061274e-01  4.49436679e-02  2.79022753e-01  9.14624855e-02\n",
            "  3.46340798e-02 -5.31036675e-01  5.49918473e-01 -1.16297074e-01\n",
            "  1.77339897e-01 -1.86684817e-01 -2.01708958e-01 -2.12172225e-01\n",
            " -3.98917586e-01 -1.43944532e-01  6.57112896e-01 -1.22864328e-01\n",
            " -1.79770797e-01 -7.51853511e-02 -3.80083442e-01 -8.02707076e-02\n",
            "  2.31385618e-01 -5.24314940e-02  1.64164409e-01  5.93767278e-02\n",
            " -2.29123738e-02  3.66135836e-02  3.59152406e-01 -2.43065089e-01\n",
            " -1.82637379e-01  1.60154924e-01 -4.14475620e-01  2.26123199e-01\n",
            "  1.71239734e-01  1.19967870e-02  2.01823324e-01  2.19359189e-01\n",
            " -9.79529601e-03 -1.05089448e-01  3.29470903e-01 -1.89605907e-01\n",
            " -2.09707528e-01  9.29182693e-02  1.89667642e-01 -9.91370454e-02\n",
            " -5.18793128e-02  2.02134252e-01 -1.71311527e-01 -4.56732303e-01\n",
            "  6.51438892e-01  4.48554337e-01 -2.54720896e-01 -3.13911527e-01\n",
            " -8.05455446e-02 -1.58698037e-01 -1.89431012e-02 -4.47671004e-02\n",
            " -2.13672027e-01  2.58633405e-01  3.76424462e-01 -2.06450880e-01\n",
            "  3.27302277e-01  1.49256542e-01 -2.64076918e-01 -2.11497754e-01\n",
            " -6.66711759e-03  9.05184299e-02  1.46651372e-01  2.86410451e-01\n",
            " -8.40569362e-02  4.57336724e-01  3.35830674e-02  3.43206972e-01\n",
            " -1.71305120e-01 -2.16286644e-01 -1.22884169e-01  7.97851086e-02\n",
            "  9.66666937e-02  9.00969952e-02  2.48120561e-01  2.32042432e-01\n",
            "  3.09389442e-01  1.71858579e-01  1.55220672e-01 -1.23914033e-01\n",
            "  8.45271289e-01  8.25401664e-01  2.07487807e-01  2.53568649e-01\n",
            " -1.89969495e-01 -2.21925497e-01  1.35195062e-01 -7.16519356e-02\n",
            " -4.48504128e-02  2.57148057e-01 -2.47548163e-01  3.82696092e-01\n",
            "  3.33175004e-01  3.54896903e-01  1.39601186e-01 -1.06218033e-01\n",
            "  5.77399647e-03  1.56661332e-01 -3.36786127e-03 -1.52124390e-01\n",
            " -5.33197641e-01  3.06708571e-02  4.29547094e-02 -1.91209123e-01\n",
            " -8.11226666e-02 -3.26077670e-01 -1.81277975e-01  3.43212336e-02\n",
            " -1.21025264e-01 -1.10748559e-01 -1.77828655e-01  2.56669730e-01\n",
            " -1.30254939e-01 -1.04853213e-01 -2.93967038e-01 -2.48595834e-01\n",
            " -3.21272731e-01 -2.46458396e-01 -1.98222890e-01 -3.34910378e-02\n",
            " -3.87853473e-01 -4.74055350e-01 -2.25469604e-01 -3.77431549e-02\n",
            " -6.06590807e-02 -3.67329210e-01 -5.23533463e-01 -2.78093517e-01\n",
            "  3.28975499e-01 -4.49429452e-02  4.00645524e-01  9.33492854e-02\n",
            "  3.36611331e-01 -3.13762605e-01 -3.65066588e-01 -1.90736592e-01\n",
            "  3.55376303e-01 -5.35379397e-03 -6.51752353e-02  3.44048113e-01\n",
            " -1.30659133e-01  3.46835822e-01 -1.22486696e-01  4.55636382e-01\n",
            " -4.35046881e-01  1.27222165e-01 -7.81522691e-02  2.25957409e-01\n",
            "  2.02506438e-01  9.11965072e-02 -3.44616584e-02  4.98090424e-02\n",
            " -2.84435511e-01 -1.29691213e-01  8.00557584e-02  1.63746215e-02\n",
            " -2.27397960e-02 -1.68332353e-01 -2.44563952e-01  9.36181918e-02\n",
            " -7.03471825e-02  5.56643531e-02 -1.40030444e-01  2.13701338e-01\n",
            " -1.98216178e-02  7.43525550e-02  9.27167106e-03 -2.79654376e-02\n",
            " -3.02103162e-01  1.24198645e-01 -1.22605138e-01  4.83761519e-01\n",
            "  3.88145357e-01  1.93261392e-02 -2.15446144e-01  2.52288222e-01\n",
            "  5.91475844e-01  5.27099241e-03  1.28351986e-01 -2.02801421e-01\n",
            " -2.17490032e-01 -3.02866459e-01 -2.63920844e-01 -2.70948142e-01\n",
            "  2.83151448e-01  7.40017816e-02  2.69439425e-02 -1.92173272e-01\n",
            " -3.59057128e-01 -3.89241517e-01 -1.76674932e-01 -1.65603146e-01]\n",
            "768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "looks good - one vector with 768 dimensions. This is what we expected the function to output."
      ],
      "metadata": {
        "id": "oRlOUZ0N3uUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate 5 random indices\n",
        "random_indices = np.random.choice(essay_df_BERT.index, size=5, replace=False)\n",
        "\n",
        "# Print the full text and preprocessed text for each random row\n",
        "for index in random_indices:\n",
        "  print(\"Row Index:\", index)\n",
        "  print(\"Full Text:\")\n",
        "  print(essay_df_BERT.loc[index, 'full_text'])\n",
        "  print(\"\\nPreprocessed Text:\")\n",
        "  print(essay_df_BERT.loc[index, 'preprocessed'])\n",
        "  print(\"\\n\" + \"=\"*50 + \"\\n\") # add a separator between rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cWYeajqLn5g",
        "outputId": "2f408565-7e32-44e7-a43f-2c44d108c97c",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row Index: 1860\n",
            "Full Text:\n",
            "Many people have different opinions about what happens on the planet Mars. During a recent discovery many people had the idea that the face on mars was created by aliens. Scientists had a different theory. Scientists believed that the face was formed by something more believable. Aliens was not one of those.\n",
            "\n",
            "On May 24th NASA's Viking 1 spacecraft was on Mars. The spacecraft was going about it's regular mission until it noticed something interesting. The text states, \"..when it spotted the shadowy likenss of a human face.\" The text states, \"A few days later NASA unveiled the image for all to see.\" Once NASA revealed the images for the world to see, many of them claimed it was from aliens. Scientists had to quickly do their research to clear up false accusations. The text states, \"Thousands of anxious web surfers were waiting when the image first appeared on a JPL web site, revealing...a natural landform. There was no alien monument after all.\" Once NASA cleared it up that it wasn't an alien monument they quickly found out what the face was. The text states, \"What the picture actually shows is the Martian equivalent of a butte or mesa---landforms common around the American West. NASA was able to put an end to the false accusations, and also support their conclusion with nautral landforms.\n",
            "\n",
            "While many people do have different opinions about certain things, sometimes those opinions can chhange. By being able to provide people with evidence as to why something is the way it is can steer thier opinion in another direction. NASA had many followers who felt that the face on Mars was caused by aliens, but NASA was quick to provide them with correct imformation on the formation of the face.\n",
            "\n",
            "Preprocessed Text:\n",
            "['many', 'people', 'different', 'opinions', 'happens', 'planet', 'mars', 'recent', 'discovery', 'many', 'people', 'idea', 'face', 'mars', 'created', 'aliens', 'scientists', 'different', 'theory', 'scientists', 'believed', 'face', 'formed', 'something', 'believable', 'aliens', 'one', 'may', 'twenty', 'fourth', 'nasa', 'viking', 'one', 'spacecraft', 'mars', 'spacecraft', 'going', 'regular', 'mission', 'noticed', 'something', 'interesting', 'text', 'states', 'spotted', 'shadowy', 'likenss', 'human', 'face', 'text', 'states', 'days', 'later', 'nasa', 'unveiled', 'image', 'see', 'nasa', 'revealed', 'images', 'world', 'see', 'many', 'claimed', 'aliens', 'scientists', 'quickly', 'research', 'clear', 'false', 'accusations', 'text', 'states', 'thousands', 'anxious', 'web', 'surfers', 'waiting', 'image', 'first', 'appeared', 'jpl', 'web', 'site', 'revealing', 'natural', 'landform', 'alien', 'monument', 'nasa', 'cleared', 'alien', 'monument', 'quickly', 'found', 'face', 'text', 'states', 'picture', 'actually', 'shows', 'martian', 'equivalent', 'butte', 'mesa', 'landforms', 'common', 'around', 'american', 'west', 'nasa', 'able', 'put', 'end', 'false', 'accusations', 'also', 'support', 'conclusion', 'nautral', 'landforms', 'many', 'people', 'different', 'opinions', 'certain', 'things', 'sometimes', 'opinions', 'chhange', 'able', 'provide', 'people', 'evidence', 'something', 'way', 'steer', 'thier', 'opinion', 'another', 'direction', 'nasa', 'many', 'followers', 'felt', 'face', 'mars', 'caused', 'aliens', 'nasa', 'quick', 'provide', 'correct', 'imformation', 'formation', 'face']\n",
            "\n",
            "==================================================\n",
            "\n",
            "Row Index: 353\n",
            "Full Text:\n",
            "In the passage \"Car-Free Cities\" Have many advantages, but i feel that the main advantage is that it is good for the planet and to lower air pollution and aslo the movement is actually working.\n",
            "\n",
            "Helping out the planet and staying green in some way is a good thing because it helps our planet look better not only that it makes it look better but it also makes us humans and the planet Earth healthier for example the air pollution can be lowered by driving cars less,instead od driving your own car you could take the bus,walk, or ride like in the text it says\n",
            "\n",
            "\"Its's a good opportunity to take away stress and lower air pollution,\" said businessman Carlos Arturo Plaza as he rode a two-seat bicycle with his wife.\"\n",
            "\n",
            "I like this piece of evidence because it tels more on how being green can not only help the planet but alo tell how it can help human kind, because it helps you understand not only it can lower pollution but it can also lower your stress, but if you choice not to go along with the movement you shouldn't have to pay a fine of 5$ because to me it seems like that would be taking away a persons rights yes i get it \"\n",
            "\n",
            "The goal is to promote altnative transportatin and reduce smog\"\n",
            "\n",
            "but a person should not be force to do so.\n",
            "\n",
            "Another advantage could be that the movement is working\n",
            "\n",
            "\"President Obama's ambitious goals to curb the United States' greenhouse gas emissions, unveiled last week, will get a fortuitous assist from an incipient shift in American behavior: recent studies suggest that Americans are buying fewer cars, driving less and getting fewer licenses as each year goes by.\n",
            "\n",
            "I like this piece of evidence from \"Source 4: The End of Car Culture\" By Elisabeth Rosenthal because it states what the president is doing to try and make our planet better, but not only that it also gives factual information by telling about fewer cars are being broughten each year and also fewer licenses are also being gotten\n",
            "\n",
            "All in all this passage have many good advantages to help persuade people to start driving less and helping out our planet, One it is good for our planet because no one wants to live in a dirty place, Two it will help lower the bad air pollution, and Lastly is that the movement is working anyways so why not try and help out and drive a little less?                    \n",
            "\n",
            "Preprocessed Text:\n",
            "['passage', 'car', 'free', 'cities', 'many', 'advantages', 'feel', 'main', 'advantage', 'good', 'planet', 'lower', 'air', 'pollution', 'aslo', 'movement', 'actually', 'working', 'helping', 'planet', 'staying', 'green', 'way', 'good', 'thing', 'helps', 'planet', 'look', 'better', 'makes', 'look', 'better', 'also', 'makes', 'us', 'humans', 'planet', 'earth', 'healthier', 'example', 'air', 'pollution', 'lowered', 'driving', 'cars', 'less', 'instead', 'od', 'driving', 'car', 'could', 'take', 'bus', 'walk', 'ride', 'like', 'text', 'says', 'good', 'opportunity', 'take', 'away', 'stress', 'lower', 'air', 'pollution', 'said', 'businessman', 'carlos', 'arturo', 'plaza', 'rode', 'two', 'seat', 'bicycle', 'wife', 'like', 'piece', 'evidence', 'tels', 'green', 'help', 'planet', 'alo', 'tell', 'help', 'human', 'kind', 'helps', 'understand', 'lower', 'pollution', 'also', 'lower', 'stress', 'choice', 'go', 'along', 'movement', 'pay', 'fine', 'five', 'seems', 'like', 'would', 'taking', 'away', 'persons', 'rights', 'yes', 'get', 'goal', 'promote', 'altnative', 'transportatin', 'reduce', 'smog', 'person', 'force', 'another', 'advantage', 'could', 'movement', 'working', 'president', 'obama', 'ambitious', 'goals', 'curb', 'united', 'states', 'greenhouse', 'gas', 'emissions', 'unveiled', 'last', 'week', 'get', 'fortuitous', 'assist', 'incipient', 'shift', 'american', 'behavior', 'recent', 'studies', 'suggest', 'americans', 'buying', 'fewer', 'cars', 'driving', 'less', 'getting', 'fewer', 'licenses', 'year', 'goes', 'like', 'piece', 'evidence', 'source', 'four', 'end', 'car', 'culture', 'elisabeth', 'rosenthal', 'states', 'president', 'try', 'make', 'planet', 'better', 'also', 'gives', 'factual', 'information', 'telling', 'fewer', 'cars', 'broughten', 'year', 'also', 'fewer', 'licenses', 'also', 'gotten', 'passage', 'many', 'good', 'advantages', 'help', 'persuade', 'people', 'start', 'driving', 'less', 'helping', 'planet', 'one', 'good', 'planet', 'one', 'wants', 'live', 'dirty', 'place', 'two', 'help', 'lower', 'bad', 'air', 'pollution', 'lastly', 'movement', 'working', 'anyways', 'try', 'help', 'drive', 'little', 'less']\n",
            "\n",
            "==================================================\n",
            "\n",
            "Row Index: 1333\n",
            "Full Text:\n",
            "Dear Florida senator,\n",
            "\n",
            "I strongly agree of keeping the Electoral College for the use of the congress' approval for the newly President of 2016. The Electoral College has a lengthy process, but can come in good use of determining the new President. Citizens vote for the electors and the electors decide who's best for the country. Even though, there are claims about the Electoral College not being fair for the people, I still defend it because it has it's good factors, like Run-off Elections,the requirement that a presidential candidate to have trans-regional appeal for the people, and the resoring weight of the eletoral number by population.\n",
            "\n",
            "As so you know, the Electoral College is a process of the selction of the electors, then the gathering of electors to vote for the president and vice president. Finally, the electoral votes by the Congress. When the electors pick the president, they look at their background, such as, what school they attend, what they studied, where they were born, etc. They pick someone they trust to do the job. When there is a Run-off Election, the House Of Representatives picks the president. I personally think this is a good thing because they picked the person who would do best in the job by gathering everyone's vote to decide it. Because no country could have two presidents with two vice presidents. Some may say it's unjustice or not fair because the House Of Representatives decides the whole election. There is also the fact that when determining the winner, they both look at the popular votes and the electoral votes, and they see who got the most electoral votes and they win the election.\n",
            "\n",
            "The Electoral College  puts it simple, because they choose someone with a region where they most likely get the most electoral votes. For example, Romney was in the South region, and he knows he wouldn't have to do much there because of that was where he was currently from. Now lets compare that to someone that was in the area around North Dakota. He would most likely not win that many votes since it's only three electoral numbers. So the Electoral College gives a chance for the president they chose to win because of where they used to be located in order to get the most popular and electoral votes.\n",
            "\n",
            "The Electoral College restores and reduces some of the weight of the electoral by its population. Smalls states aren't widely noticed by the president because they feel like they should concentrated in the big states because of there electoral votes. Still, small states tend to make it easier for them because they look at if the state was either Republican or Democrac during the past years and they take note of that. They know they'll win in those states, even though they are small numbers, every inch of it counts to help them win the title of President.\n",
            "\n",
            "Therefore, Mister Sentor, I agree in keeping the Electoral Vote because of it's reasonable factors that can help the president win. Popular vote doesn't tell anything because the people would know nothing about the president or what he accomplished. It should be kept because it has been used for many years now and has been useful for every president to win.\n",
            "\n",
            "To Whom I Name,\n",
            "\n",
            "V.                                \n",
            "\n",
            "Preprocessed Text:\n",
            "['dear', 'florida', 'senator', 'strongly', 'agree', 'keeping', 'electoral', 'college', 'use', 'congress', 'approval', 'newly', 'president', 'two', 'thousand', 'sixteen', 'electoral', 'college', 'lengthy', 'process', 'come', 'good', 'use', 'determining', 'new', 'president', 'citizens', 'vote', 'electors', 'electors', 'decide', 'best', 'country', 'even', 'though', 'claims', 'electoral', 'college', 'fair', 'people', 'still', 'defend', 'good', 'factors', 'like', 'run', 'elections', 'requirement', 'presidential', 'candidate', 'trans', 'regional', 'appeal', 'people', 'resoring', 'weight', 'eletoral', 'number', 'population', 'know', 'electoral', 'college', 'process', 'selction', 'electors', 'gathering', 'electors', 'vote', 'president', 'vice', 'president', 'finally', 'electoral', 'votes', 'congress', 'electors', 'pick', 'president', 'look', 'background', 'school', 'attend', 'studied', 'born', 'etc', 'pick', 'someone', 'trust', 'job', 'run', 'election', 'house', 'representatives', 'picks', 'president', 'personally', 'think', 'good', 'thing', 'picked', 'person', 'would', 'best', 'job', 'gathering', 'everyone', 'vote', 'decide', 'country', 'could', 'two', 'presidents', 'two', 'vice', 'presidents', 'may', 'say', 'unjustice', 'fair', 'house', 'representatives', 'decides', 'whole', 'election', 'also', 'fact', 'determining', 'winner', 'look', 'popular', 'votes', 'electoral', 'votes', 'see', 'got', 'electoral', 'votes', 'win', 'election', 'electoral', 'college', 'puts', 'simple', 'choose', 'someone', 'region', 'likely', 'get', 'electoral', 'votes', 'example', 'romney', 'south', 'region', 'knows', 'would', 'much', 'currently', 'let', 'us', 'compare', 'someone', 'area', 'around', 'north', 'dakota', 'would', 'likely', 'win', 'many', 'votes', 'since', 'three', 'electoral', 'numbers', 'electoral', 'college', 'gives', 'chance', 'president', 'chose', 'win', 'used', 'located', 'order', 'get', 'popular', 'electoral', 'votes', 'electoral', 'college', 'restores', 'reduces', 'weight', 'electoral', 'population', 'smalls', 'states', 'widely', 'noticed', 'president', 'feel', 'like', 'concentrated', 'big', 'states', 'electoral', 'votes', 'still', 'small', 'states', 'tend', 'make', 'easier', 'look', 'state', 'either', 'republican', 'democrac', 'past', 'years', 'take', 'note', 'know', 'win', 'states', 'even', 'though', 'small', 'numbers', 'every', 'inch', 'counts', 'help', 'win', 'title', 'president', 'therefore', 'mister', 'sentor', 'agree', 'keeping', 'electoral', 'vote', 'reasonable', 'factors', 'help', 'president', 'win', 'popular', 'vote', 'tell', 'anything', 'people', 'would', 'know', 'nothing', 'president', 'accomplished', 'kept', 'used', 'many', 'years', 'useful', 'every', 'president', 'win', 'name', 'v']\n",
            "\n",
            "==================================================\n",
            "\n",
            "Row Index: 905\n",
            "Full Text:\n",
            "Isn't it crazy that a face on Mars would be created by aliens? NASA sure seems to think it is. Many sciensts have discovered it's a natural landform.\n",
            "\n",
            "The face on Mars is indeed a natural landfom. NASA has had the Mars Global Survayor fly over Cydonia and take pictures to prove it, as Jim Garvin has said,\"We photographed the Face as soon as we could get a good shot of it.\"\n",
            "\n",
            "Many people will say that the face on Mars was created by previous creatures living there. The planet humans live on, Earth, even has landforms that humans didnt make that just happen to look like faces, As Garvin says,\"It reminds me most of Middle Butte in the Snake River Plain of Idaho.\" The face on Mars is nothing but land that has been formed in the shape of a face.\n",
            "\n",
            "The face on Mars has been proven to be a landform. They have taken pictures, the scientists have studied it, and all these studies have proved that the face is just land. In conclusion, sometimes things aren't as they seem.\n",
            "\n",
            "Preprocessed Text:\n",
            "['crazy', 'face', 'mars', 'would', 'created', 'aliens', 'nasa', 'sure', 'seems', 'think', 'many', 'sciensts', 'discovered', 'natural', 'landform', 'face', 'mars', 'indeed', 'natural', 'landfom', 'nasa', 'mars', 'global', 'survayor', 'fly', 'cydonia', 'take', 'pictures', 'prove', 'jim', 'garvin', 'said', 'photographed', 'face', 'soon', 'could', 'get', 'good', 'shot', 'many', 'people', 'say', 'face', 'mars', 'created', 'previous', 'creatures', 'living', 'planet', 'humans', 'live', 'earth', 'even', 'landforms', 'humans', 'make', 'happen', 'look', 'like', 'faces', 'garvin', 'says', 'reminds', 'middle', 'butte', 'snake', 'river', 'plain', 'idaho', 'face', 'mars', 'nothing', 'land', 'formed', 'shape', 'face', 'face', 'mars', 'proven', 'landform', 'taken', 'pictures', 'scientists', 'studied', 'studies', 'proved', 'face', 'land', 'conclusion', 'sometimes', 'things', 'seem']\n",
            "\n",
            "==================================================\n",
            "\n",
            "Row Index: 1289\n",
            "Full Text:\n",
            "The Beginning Of A Car-Free World\n",
            "\n",
            "Cars are an integral part of society today, from the hustling bustling cities to far out in the countryside, these machines can be found everywhere, but lately there has been a new trend spreading across the modern world: The limitations on cars.\n",
            "\n",
            "The use of cars is steadily decreasing throughout the Americas and Western Europe. Germany home to the most advanced car-free suburban community VAUBAN. VAUBAN is the pinnacle of modern car-free suburban living, the new area lies just outside of Freiburg, providing a near complete self sufficient way of living, without relying on the use of cars. As the case with most suburban residences, getting to and from the urban cities is nessessary due to the need to restock food and get to work. In the case of this city it has significantly reduced the emitions from vehicles via public transport and the erection of several shops, just walking distance from the community.\n",
            "\n",
            "Due to the smog caused by the rise of pollution by the emitions of vehicles, Paris made an attempt to ban cars from its streets, alternating between even numbered and odd numbered liscense plates. The ban sparked outrage among the citizens over the strictness of the ban, but the effects were worthwhile as the smog had cleared up enough for the ban to be lifted.\n",
            "\n",
            "The limitations on carsare not just restricted to Europe, the Americas have also taken an intrest in reducing the pollution caused by cars. In 2002 BOGOTA, Colombia, for the third year in a row had a day completely devoid of cars. The participants, all of Bogota's 7 million citzens, used seperate means of transportation to cut the emitions released by cars, only permitting the use of buses and taxis as vehicular transportation.\n",
            "\n",
            "In the U.S. the use of cars is on the decline, with the number of miles driven per person dropping 9% as of April 2013 to record lows scince January 1995. This decrease is caused in part by the recovering economy and the arrival of new methods of keeping in touch. The executive chairman of the Ford Motor Company, Bill Ford, has proposed a plan to create a world where the personal ownership of a vehicle would be in his words \"impractical and undesirable.\"\n",
            "\n",
            "In this new age of awareness to the effects of pollution and the means to fight against them, these limitations may be the first steps on a long journey to the restoration of our planet.    \n",
            "\n",
            "Preprocessed Text:\n",
            "['beginning', 'car', 'free', 'world', 'cars', 'integral', 'part', 'society', 'today', 'hustling', 'bustling', 'cities', 'far', 'countryside', 'machines', 'found', 'everywhere', 'lately', 'new', 'trend', 'spreading', 'across', 'modern', 'world', 'limitations', 'cars', 'use', 'cars', 'steadily', 'decreasing', 'throughout', 'americas', 'western', 'europe', 'germany', 'home', 'advanced', 'car', 'free', 'suburban', 'community', 'vauban', 'vauban', 'pinnacle', 'modern', 'car', 'free', 'suburban', 'living', 'new', 'area', 'lies', 'outside', 'freiburg', 'providing', 'near', 'complete', 'self', 'sufficient', 'way', 'living', 'without', 'relying', 'use', 'cars', 'case', 'suburban', 'residences', 'getting', 'urban', 'cities', 'nessessary', 'due', 'need', 'restock', 'food', 'get', 'work', 'case', 'city', 'significantly', 'reduced', 'emitions', 'vehicles', 'via', 'public', 'transport', 'erection', 'several', 'shops', 'walking', 'distance', 'community', 'due', 'smog', 'caused', 'rise', 'pollution', 'emitions', 'vehicles', 'paris', 'made', 'attempt', 'ban', 'cars', 'streets', 'alternating', 'even', 'numbered', 'odd', 'numbered', 'liscense', 'plates', 'ban', 'sparked', 'outrage', 'among', 'citizens', 'strictness', 'ban', 'effects', 'worthwhile', 'smog', 'cleared', 'enough', 'ban', 'lifted', 'limitations', 'carsare', 'restricted', 'europe', 'americas', 'also', 'taken', 'intrest', 'reducing', 'pollution', 'caused', 'cars', 'two', 'thousand', 'two', 'bogota', 'colombia', 'third', 'year', 'row', 'day', 'completely', 'devoid', 'cars', 'participants', 'bogota', 'seven', 'million', 'citzens', 'used', 'seperate', 'means', 'transportation', 'cut', 'emitions', 'released', 'cars', 'permitting', 'use', 'buses', 'taxis', 'vehicular', 'transportation', 'use', 'cars', 'decline', 'number', 'miles', 'driven', 'per', 'person', 'dropping', 'nine', 'april', 'two', 'thousand', 'thirteen', 'record', 'lows', 'scince', 'january', 'one', 'thousand', 'nine', 'hundred', 'ninety', 'five', 'decrease', 'caused', 'part', 'recovering', 'economy', 'arrival', 'new', 'methods', 'keeping', 'touch', 'executive', 'chairman', 'ford', 'motor', 'company', 'bill', 'ford', 'proposed', 'plan', 'create', 'world', 'personal', 'ownership', 'vehicle', 'would', 'words', 'impractical', 'undesirable', 'new', 'age', 'awareness', 'effects', 'pollution', 'means', 'fight', 'limitations', 'may', 'first', 'steps', 'long', 'journey', 'restoration', 'planet']\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a check with the preprocessed and the full text next to each other to be sure that the preprocessing worked the way that it was suppoed to - the preprocessed text is a list of strings; exactly what we expect."
      ],
      "metadata": {
        "id": "E-bQdjZO38s3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data for Keras model\n",
        "X = np.stack(essay_df_BERT['bert_embeddings'].values)\n",
        "y = essay_df_BERT['score'].values\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# One-hot encode the target labels\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "# categorical data (score/grade)\n",
        "# Step 1: Convert grade to integer labels\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Step 2: Reshape the data to be a 2D array as required by OneHotEncoder\n",
        "integer_encoded = integer_encoded.reshape(-1, 1)\n",
        "\n",
        "# Step 3: Apply OneHotEncoder\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "y_one_hot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "\n",
        "# Print the results\n",
        "print(\"Original Categories:\", y)\n",
        "print(\"Integer Encoded:\", integer_encoded.ravel())\n",
        "print(\"One-Hot Encoded:\\n\", y_one_hot_encoded)\n",
        "#.unique\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot_encoded, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "F4ancr6TSIUa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8af7b72a-432a-474f-dbd9-913dbc821091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Categories: [3 3 4 ... 4 2 3]\n",
            "Integer Encoded: [2 2 3 ... 3 1 2]\n",
            "One-Hot Encoded:\n",
            " [[0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When fine-tuning transformer-based models like BERT for essay scoring to align with a grading rubric, several hyperparameters can be adjusted to optimize performance:\n",
        "\n",
        "Learning Rate: This hyperparameter controls the step size during the optimization process. It can be tuned to ensure that the model learns at an appropriate pace, effectively updating its parameters to minimize the loss function.\n",
        "\n",
        "Batch Size: The batch size determines the number of samples processed in each training iteration. Adjusting this hyperparameter can impact the model's generalization ability and training speed.\n",
        "\n",
        "Number of Training Epochs: The number of training epochs specifies how many times the entire training dataset is passed through the model. Fine-tuning may require experimenting with different numbers of epochs to achieve optimal performance without overfitting.\n",
        "\n",
        "Dropout Rate: Dropout is a regularization technique that randomly drops a fraction of input units during training to prevent overfitting. Tuning the dropout rate can help balance model complexity and generalization.\n",
        "\n",
        "Layer-specific Hyperparameters: Some transformer architectures, such as BERT, have multiple layers with their own hyperparameters, such as the number of attention heads, hidden units, and feedforward layer sizes. Fine-tuning these parameters can be beneficial for adapting the model to specific tasks and datasets."
      ],
      "metadata": {
        "id": "SGGllqMWePA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and compile a simple Keras model\n",
        "input_dim = X_train.shape[1] #number of features\n",
        "#dimensionality of the vectors is specified [1] chooses which feature in the set\n",
        "\n",
        "#multiclass\n",
        "#Number of classes\n",
        "num_classes = y_one_hot_encoded.shape[1] #number of classes\n",
        "\n",
        "\n",
        "# Build and compile a simple Keras model for multiclass classification\n",
        "#like specificying how each split decision is made in a decision tree\n",
        "inputs = Input(shape=(input_dim,)) #input layer; shape 768 dimensions; setting up an empty framework\n",
        "x = Dense(128, activation='relu')(inputs) # x=hidden layer; each input gets an additional hidden layer added to the previous group\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)  # Softmax activation for multiclass classification\n",
        "\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "#multiclass\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#optimizer = AdamW(model.parameters(), lr=learning_rate), consider tuning these in future\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "OxxRkfthSJIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d2d50be-a4f3-42e0-de57-0bd5a5ee420d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 768)]             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               98432     \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6)                 390       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 107,078\n",
            "Trainable params: 107,078\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training\n"
      ],
      "metadata": {
        "id": "NnTuAJRDAE_J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictions are probabilities of which class (grade) the essay will be placed in"
      ],
      "metadata": {
        "id": "QgIEaP_MgQLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# step 4: Build and Train the Neural Network Model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500, batch_size=32, validation_split=0.2)\n",
        "\n",
        "#multiclass\n",
        "# Predictions on training and test data\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "print (y_train_pred)\n",
        "print (y_test_pred)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEQvrLOWNqkI",
        "outputId": "5ae34c47-54ce-499e-bc71-97e5fd799f71",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "40/40 [==============================] - 1s 14ms/step - loss: 1.5918 - accuracy: 0.3250 - val_loss: 1.4491 - val_accuracy: 0.3688\n",
            "Epoch 2/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 1.4804 - accuracy: 0.3523 - val_loss: 1.3820 - val_accuracy: 0.4156\n",
            "Epoch 3/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 1.4022 - accuracy: 0.4117 - val_loss: 1.3223 - val_accuracy: 0.5031\n",
            "Epoch 4/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 1.3266 - accuracy: 0.4273 - val_loss: 1.2302 - val_accuracy: 0.4656\n",
            "Epoch 5/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.2447 - accuracy: 0.4891 - val_loss: 1.1526 - val_accuracy: 0.5312\n",
            "Epoch 6/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.2173 - accuracy: 0.4984 - val_loss: 1.1488 - val_accuracy: 0.5469\n",
            "Epoch 7/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.2038 - accuracy: 0.5141 - val_loss: 1.1214 - val_accuracy: 0.5375\n",
            "Epoch 8/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.1597 - accuracy: 0.5047 - val_loss: 1.0940 - val_accuracy: 0.5531\n",
            "Epoch 9/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.1478 - accuracy: 0.5039 - val_loss: 1.1207 - val_accuracy: 0.5125\n",
            "Epoch 10/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.1367 - accuracy: 0.5336 - val_loss: 1.1002 - val_accuracy: 0.5312\n",
            "Epoch 11/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.1264 - accuracy: 0.4961 - val_loss: 1.1204 - val_accuracy: 0.5312\n",
            "Epoch 12/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.1134 - accuracy: 0.5266 - val_loss: 1.0699 - val_accuracy: 0.5531\n",
            "Epoch 13/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.1007 - accuracy: 0.5242 - val_loss: 1.0840 - val_accuracy: 0.5562\n",
            "Epoch 14/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0879 - accuracy: 0.5383 - val_loss: 1.0704 - val_accuracy: 0.5562\n",
            "Epoch 15/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0655 - accuracy: 0.5477 - val_loss: 1.0531 - val_accuracy: 0.5594\n",
            "Epoch 16/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 1.0735 - accuracy: 0.5516 - val_loss: 1.0327 - val_accuracy: 0.5781\n",
            "Epoch 17/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0538 - accuracy: 0.5555 - val_loss: 1.1147 - val_accuracy: 0.5344\n",
            "Epoch 18/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0581 - accuracy: 0.5500 - val_loss: 1.0353 - val_accuracy: 0.5500\n",
            "Epoch 19/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0509 - accuracy: 0.5422 - val_loss: 1.1333 - val_accuracy: 0.4938\n",
            "Epoch 20/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0314 - accuracy: 0.5609 - val_loss: 1.0967 - val_accuracy: 0.5219\n",
            "Epoch 21/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0152 - accuracy: 0.5625 - val_loss: 1.0486 - val_accuracy: 0.5656\n",
            "Epoch 22/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0488 - accuracy: 0.5359 - val_loss: 1.0523 - val_accuracy: 0.5875\n",
            "Epoch 23/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9892 - accuracy: 0.5594 - val_loss: 1.0542 - val_accuracy: 0.5656\n",
            "Epoch 24/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 1.0038 - accuracy: 0.5773 - val_loss: 1.0248 - val_accuracy: 0.5656\n",
            "Epoch 25/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9542 - accuracy: 0.5828 - val_loss: 1.0920 - val_accuracy: 0.5375\n",
            "Epoch 26/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9798 - accuracy: 0.5898 - val_loss: 1.0687 - val_accuracy: 0.5469\n",
            "Epoch 27/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9600 - accuracy: 0.5977 - val_loss: 1.0524 - val_accuracy: 0.5344\n",
            "Epoch 28/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9548 - accuracy: 0.5945 - val_loss: 1.0334 - val_accuracy: 0.5781\n",
            "Epoch 29/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9496 - accuracy: 0.6070 - val_loss: 1.0666 - val_accuracy: 0.5469\n",
            "Epoch 30/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9591 - accuracy: 0.5930 - val_loss: 1.0753 - val_accuracy: 0.5531\n",
            "Epoch 31/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9660 - accuracy: 0.5773 - val_loss: 1.0251 - val_accuracy: 0.5625\n",
            "Epoch 32/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9346 - accuracy: 0.6000 - val_loss: 1.0774 - val_accuracy: 0.5437\n",
            "Epoch 33/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9471 - accuracy: 0.5836 - val_loss: 1.0472 - val_accuracy: 0.5750\n",
            "Epoch 34/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9520 - accuracy: 0.5883 - val_loss: 1.0385 - val_accuracy: 0.5688\n",
            "Epoch 35/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9485 - accuracy: 0.5750 - val_loss: 1.0801 - val_accuracy: 0.5312\n",
            "Epoch 36/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9538 - accuracy: 0.6016 - val_loss: 1.0161 - val_accuracy: 0.5531\n",
            "Epoch 37/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9257 - accuracy: 0.6023 - val_loss: 1.0210 - val_accuracy: 0.5844\n",
            "Epoch 38/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9267 - accuracy: 0.5969 - val_loss: 1.0351 - val_accuracy: 0.5750\n",
            "Epoch 39/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9126 - accuracy: 0.6125 - val_loss: 1.0798 - val_accuracy: 0.5375\n",
            "Epoch 40/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9523 - accuracy: 0.5922 - val_loss: 1.0557 - val_accuracy: 0.5406\n",
            "Epoch 41/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.9005 - accuracy: 0.5977 - val_loss: 1.0510 - val_accuracy: 0.5656\n",
            "Epoch 42/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8906 - accuracy: 0.6211 - val_loss: 1.0479 - val_accuracy: 0.5844\n",
            "Epoch 43/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9138 - accuracy: 0.6094 - val_loss: 1.0407 - val_accuracy: 0.5625\n",
            "Epoch 44/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8743 - accuracy: 0.6336 - val_loss: 1.0486 - val_accuracy: 0.5594\n",
            "Epoch 45/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9066 - accuracy: 0.6172 - val_loss: 1.0531 - val_accuracy: 0.5688\n",
            "Epoch 46/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9015 - accuracy: 0.6055 - val_loss: 1.1132 - val_accuracy: 0.5219\n",
            "Epoch 47/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8894 - accuracy: 0.6164 - val_loss: 1.0476 - val_accuracy: 0.5688\n",
            "Epoch 48/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8956 - accuracy: 0.6305 - val_loss: 1.0300 - val_accuracy: 0.5500\n",
            "Epoch 49/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8679 - accuracy: 0.6297 - val_loss: 1.0521 - val_accuracy: 0.5562\n",
            "Epoch 50/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8769 - accuracy: 0.6289 - val_loss: 1.0722 - val_accuracy: 0.5344\n",
            "Epoch 51/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8766 - accuracy: 0.6305 - val_loss: 1.0592 - val_accuracy: 0.5594\n",
            "Epoch 52/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8915 - accuracy: 0.6117 - val_loss: 1.0293 - val_accuracy: 0.5594\n",
            "Epoch 53/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8839 - accuracy: 0.6219 - val_loss: 1.0520 - val_accuracy: 0.5750\n",
            "Epoch 54/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.9038 - accuracy: 0.6031 - val_loss: 1.0519 - val_accuracy: 0.5500\n",
            "Epoch 55/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8538 - accuracy: 0.6383 - val_loss: 1.0750 - val_accuracy: 0.5594\n",
            "Epoch 56/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8370 - accuracy: 0.6445 - val_loss: 1.0796 - val_accuracy: 0.5406\n",
            "Epoch 57/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8314 - accuracy: 0.6359 - val_loss: 1.0704 - val_accuracy: 0.5688\n",
            "Epoch 58/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8565 - accuracy: 0.6344 - val_loss: 1.0291 - val_accuracy: 0.5594\n",
            "Epoch 59/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8545 - accuracy: 0.6375 - val_loss: 1.0287 - val_accuracy: 0.5719\n",
            "Epoch 60/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8265 - accuracy: 0.6438 - val_loss: 1.1512 - val_accuracy: 0.5312\n",
            "Epoch 61/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8229 - accuracy: 0.6500 - val_loss: 1.0665 - val_accuracy: 0.5688\n",
            "Epoch 62/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8061 - accuracy: 0.6531 - val_loss: 1.0648 - val_accuracy: 0.5625\n",
            "Epoch 63/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8052 - accuracy: 0.6523 - val_loss: 1.0954 - val_accuracy: 0.5469\n",
            "Epoch 64/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.8195 - accuracy: 0.6320 - val_loss: 1.0689 - val_accuracy: 0.5625\n",
            "Epoch 65/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.7935 - accuracy: 0.6453 - val_loss: 1.0785 - val_accuracy: 0.5406\n",
            "Epoch 66/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.8221 - accuracy: 0.6469 - val_loss: 1.1111 - val_accuracy: 0.5344\n",
            "Epoch 67/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.8008 - accuracy: 0.6609 - val_loss: 1.0783 - val_accuracy: 0.5594\n",
            "Epoch 68/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.7974 - accuracy: 0.6523 - val_loss: 1.1004 - val_accuracy: 0.5531\n",
            "Epoch 69/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.7781 - accuracy: 0.6516 - val_loss: 1.0886 - val_accuracy: 0.5688\n",
            "Epoch 70/500\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.7824 - accuracy: 0.6727 - val_loss: 1.1037 - val_accuracy: 0.5719\n",
            "Epoch 71/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.7853 - accuracy: 0.6641 - val_loss: 1.0775 - val_accuracy: 0.5594\n",
            "Epoch 72/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.7859 - accuracy: 0.6562 - val_loss: 1.0972 - val_accuracy: 0.5562\n",
            "Epoch 73/500\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.7807 - accuracy: 0.6562 - val_loss: 1.0752 - val_accuracy: 0.5625\n",
            "Epoch 74/500\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.7855 - accuracy: 0.6750 - val_loss: 1.1263 - val_accuracy: 0.5531\n",
            "Epoch 75/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.8127 - accuracy: 0.6391 - val_loss: 1.1291 - val_accuracy: 0.5625\n",
            "Epoch 76/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.7590 - accuracy: 0.6789 - val_loss: 1.1419 - val_accuracy: 0.5531\n",
            "Epoch 77/500\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.8122 - accuracy: 0.6672 - val_loss: 1.0863 - val_accuracy: 0.5469\n",
            "Epoch 78/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7647 - accuracy: 0.6812 - val_loss: 1.1037 - val_accuracy: 0.5500\n",
            "Epoch 79/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7577 - accuracy: 0.6781 - val_loss: 1.0864 - val_accuracy: 0.5719\n",
            "Epoch 80/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7510 - accuracy: 0.6828 - val_loss: 1.1365 - val_accuracy: 0.5437\n",
            "Epoch 81/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7432 - accuracy: 0.6789 - val_loss: 1.1759 - val_accuracy: 0.5437\n",
            "Epoch 82/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7507 - accuracy: 0.6836 - val_loss: 1.0925 - val_accuracy: 0.5844\n",
            "Epoch 83/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7395 - accuracy: 0.6805 - val_loss: 1.1470 - val_accuracy: 0.5594\n",
            "Epoch 84/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7437 - accuracy: 0.6820 - val_loss: 1.1106 - val_accuracy: 0.5719\n",
            "Epoch 85/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7124 - accuracy: 0.6898 - val_loss: 1.1186 - val_accuracy: 0.5531\n",
            "Epoch 86/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7232 - accuracy: 0.6875 - val_loss: 1.1483 - val_accuracy: 0.5625\n",
            "Epoch 87/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.7109 - accuracy: 0.7000 - val_loss: 1.1929 - val_accuracy: 0.5656\n",
            "Epoch 88/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7379 - accuracy: 0.6898 - val_loss: 1.1646 - val_accuracy: 0.5500\n",
            "Epoch 89/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7225 - accuracy: 0.6898 - val_loss: 1.2044 - val_accuracy: 0.5375\n",
            "Epoch 90/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7322 - accuracy: 0.6750 - val_loss: 1.1688 - val_accuracy: 0.5813\n",
            "Epoch 91/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7136 - accuracy: 0.6750 - val_loss: 1.1218 - val_accuracy: 0.5531\n",
            "Epoch 92/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7285 - accuracy: 0.6969 - val_loss: 1.1631 - val_accuracy: 0.5719\n",
            "Epoch 93/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.7238 - accuracy: 0.6992 - val_loss: 1.1807 - val_accuracy: 0.5781\n",
            "Epoch 94/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6840 - accuracy: 0.7070 - val_loss: 1.2117 - val_accuracy: 0.5437\n",
            "Epoch 95/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7072 - accuracy: 0.6969 - val_loss: 1.1285 - val_accuracy: 0.5594\n",
            "Epoch 96/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6960 - accuracy: 0.7063 - val_loss: 1.2123 - val_accuracy: 0.5750\n",
            "Epoch 97/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7322 - accuracy: 0.6828 - val_loss: 1.1886 - val_accuracy: 0.5625\n",
            "Epoch 98/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7180 - accuracy: 0.6992 - val_loss: 1.1568 - val_accuracy: 0.5750\n",
            "Epoch 99/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7131 - accuracy: 0.7039 - val_loss: 1.1618 - val_accuracy: 0.5625\n",
            "Epoch 100/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.7070 - val_loss: 1.2523 - val_accuracy: 0.5562\n",
            "Epoch 101/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7090 - accuracy: 0.7086 - val_loss: 1.1294 - val_accuracy: 0.5844\n",
            "Epoch 102/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7079 - accuracy: 0.6844 - val_loss: 1.2693 - val_accuracy: 0.5344\n",
            "Epoch 103/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.7125 - val_loss: 1.1384 - val_accuracy: 0.5656\n",
            "Epoch 104/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6811 - accuracy: 0.7086 - val_loss: 1.1491 - val_accuracy: 0.5719\n",
            "Epoch 105/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6824 - accuracy: 0.7078 - val_loss: 1.1985 - val_accuracy: 0.5625\n",
            "Epoch 106/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.7188 - val_loss: 1.1931 - val_accuracy: 0.5437\n",
            "Epoch 107/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.7131 - accuracy: 0.7023 - val_loss: 1.1915 - val_accuracy: 0.5250\n",
            "Epoch 108/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.7133 - val_loss: 1.2373 - val_accuracy: 0.5500\n",
            "Epoch 109/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.7281 - val_loss: 1.2908 - val_accuracy: 0.5469\n",
            "Epoch 110/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6649 - accuracy: 0.7055 - val_loss: 1.2703 - val_accuracy: 0.5437\n",
            "Epoch 111/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6437 - accuracy: 0.7156 - val_loss: 1.2296 - val_accuracy: 0.5375\n",
            "Epoch 112/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.7102 - val_loss: 1.2735 - val_accuracy: 0.5437\n",
            "Epoch 113/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6886 - accuracy: 0.7141 - val_loss: 1.1585 - val_accuracy: 0.5656\n",
            "Epoch 114/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6856 - accuracy: 0.7008 - val_loss: 1.1766 - val_accuracy: 0.5719\n",
            "Epoch 115/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6640 - accuracy: 0.7125 - val_loss: 1.3156 - val_accuracy: 0.5281\n",
            "Epoch 116/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6367 - accuracy: 0.7258 - val_loss: 1.3080 - val_accuracy: 0.5625\n",
            "Epoch 117/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6503 - accuracy: 0.7180 - val_loss: 1.1654 - val_accuracy: 0.5656\n",
            "Epoch 118/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6296 - accuracy: 0.7523 - val_loss: 1.2716 - val_accuracy: 0.5594\n",
            "Epoch 119/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6672 - accuracy: 0.7156 - val_loss: 1.3262 - val_accuracy: 0.5719\n",
            "Epoch 120/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.7242 - val_loss: 1.2766 - val_accuracy: 0.5719\n",
            "Epoch 121/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6518 - accuracy: 0.7133 - val_loss: 1.2872 - val_accuracy: 0.5594\n",
            "Epoch 122/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6232 - accuracy: 0.7320 - val_loss: 1.3798 - val_accuracy: 0.5688\n",
            "Epoch 123/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.7141 - val_loss: 1.3217 - val_accuracy: 0.5406\n",
            "Epoch 124/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.7219 - val_loss: 1.2158 - val_accuracy: 0.5562\n",
            "Epoch 125/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6333 - accuracy: 0.7281 - val_loss: 1.2915 - val_accuracy: 0.5656\n",
            "Epoch 126/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6674 - accuracy: 0.7195 - val_loss: 1.2740 - val_accuracy: 0.5625\n",
            "Epoch 127/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.7141 - val_loss: 1.2959 - val_accuracy: 0.5562\n",
            "Epoch 128/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6637 - accuracy: 0.7180 - val_loss: 1.2390 - val_accuracy: 0.5281\n",
            "Epoch 129/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.7234 - val_loss: 1.2767 - val_accuracy: 0.5750\n",
            "Epoch 130/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6312 - accuracy: 0.7188 - val_loss: 1.2709 - val_accuracy: 0.5688\n",
            "Epoch 131/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.7273 - val_loss: 1.2866 - val_accuracy: 0.5437\n",
            "Epoch 132/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.7406 - val_loss: 1.1934 - val_accuracy: 0.5531\n",
            "Epoch 133/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6362 - accuracy: 0.7375 - val_loss: 1.2776 - val_accuracy: 0.5594\n",
            "Epoch 134/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6443 - accuracy: 0.7180 - val_loss: 1.2914 - val_accuracy: 0.6031\n",
            "Epoch 135/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6304 - accuracy: 0.7336 - val_loss: 1.3117 - val_accuracy: 0.5531\n",
            "Epoch 136/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.7328 - val_loss: 1.3357 - val_accuracy: 0.5562\n",
            "Epoch 137/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6453 - accuracy: 0.7352 - val_loss: 1.2348 - val_accuracy: 0.5750\n",
            "Epoch 138/500\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6149 - accuracy: 0.7297 - val_loss: 1.3793 - val_accuracy: 0.5750\n",
            "Epoch 139/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5865 - accuracy: 0.7500 - val_loss: 1.2991 - val_accuracy: 0.5688\n",
            "Epoch 140/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6245 - accuracy: 0.7391 - val_loss: 1.3432 - val_accuracy: 0.5688\n",
            "Epoch 141/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6330 - accuracy: 0.7281 - val_loss: 1.3116 - val_accuracy: 0.5719\n",
            "Epoch 142/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.6232 - accuracy: 0.7430 - val_loss: 1.3942 - val_accuracy: 0.5625\n",
            "Epoch 143/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5864 - accuracy: 0.7523 - val_loss: 1.4719 - val_accuracy: 0.5625\n",
            "Epoch 144/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5902 - accuracy: 0.7422 - val_loss: 1.3598 - val_accuracy: 0.5750\n",
            "Epoch 145/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.6036 - accuracy: 0.7516 - val_loss: 1.4312 - val_accuracy: 0.5406\n",
            "Epoch 146/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5959 - accuracy: 0.7570 - val_loss: 1.2685 - val_accuracy: 0.5938\n",
            "Epoch 147/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6028 - accuracy: 0.7359 - val_loss: 1.4576 - val_accuracy: 0.5688\n",
            "Epoch 148/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6053 - accuracy: 0.7312 - val_loss: 1.2678 - val_accuracy: 0.5813\n",
            "Epoch 149/500\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6381 - accuracy: 0.7195 - val_loss: 1.3772 - val_accuracy: 0.5375\n",
            "Epoch 150/500\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.6436 - accuracy: 0.7195 - val_loss: 1.4907 - val_accuracy: 0.5625\n",
            "Epoch 151/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.6086 - accuracy: 0.7359 - val_loss: 1.4785 - val_accuracy: 0.5531\n",
            "Epoch 152/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6100 - accuracy: 0.7555 - val_loss: 1.4922 - val_accuracy: 0.5156\n",
            "Epoch 153/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6087 - accuracy: 0.7398 - val_loss: 1.3843 - val_accuracy: 0.5594\n",
            "Epoch 154/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6309 - accuracy: 0.7312 - val_loss: 1.5316 - val_accuracy: 0.5562\n",
            "Epoch 155/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.7469 - val_loss: 1.3565 - val_accuracy: 0.5625\n",
            "Epoch 156/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6076 - accuracy: 0.7445 - val_loss: 1.4301 - val_accuracy: 0.5469\n",
            "Epoch 157/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6228 - accuracy: 0.7328 - val_loss: 1.3583 - val_accuracy: 0.5500\n",
            "Epoch 158/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.7102 - val_loss: 1.4503 - val_accuracy: 0.5375\n",
            "Epoch 159/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.7289 - val_loss: 1.3925 - val_accuracy: 0.5500\n",
            "Epoch 160/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6108 - accuracy: 0.7367 - val_loss: 1.2973 - val_accuracy: 0.5906\n",
            "Epoch 161/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.6004 - accuracy: 0.7469 - val_loss: 1.4109 - val_accuracy: 0.5406\n",
            "Epoch 162/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5887 - accuracy: 0.7453 - val_loss: 1.5621 - val_accuracy: 0.5594\n",
            "Epoch 163/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.6172 - accuracy: 0.7453 - val_loss: 1.4513 - val_accuracy: 0.5719\n",
            "Epoch 164/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5883 - accuracy: 0.7461 - val_loss: 1.3517 - val_accuracy: 0.5688\n",
            "Epoch 165/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5917 - accuracy: 0.7469 - val_loss: 1.4650 - val_accuracy: 0.5625\n",
            "Epoch 166/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5879 - accuracy: 0.7570 - val_loss: 1.5096 - val_accuracy: 0.5625\n",
            "Epoch 167/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5449 - accuracy: 0.7734 - val_loss: 1.4835 - val_accuracy: 0.5437\n",
            "Epoch 168/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5675 - accuracy: 0.7555 - val_loss: 1.4366 - val_accuracy: 0.5656\n",
            "Epoch 169/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5422 - accuracy: 0.7625 - val_loss: 1.4069 - val_accuracy: 0.5625\n",
            "Epoch 170/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.7586 - val_loss: 1.4880 - val_accuracy: 0.5688\n",
            "Epoch 171/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5392 - accuracy: 0.7672 - val_loss: 1.5771 - val_accuracy: 0.5625\n",
            "Epoch 172/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5468 - accuracy: 0.7656 - val_loss: 1.4970 - val_accuracy: 0.5562\n",
            "Epoch 173/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.7547 - val_loss: 1.5644 - val_accuracy: 0.5469\n",
            "Epoch 174/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5335 - accuracy: 0.7719 - val_loss: 1.7086 - val_accuracy: 0.5594\n",
            "Epoch 175/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.7625 - val_loss: 1.5465 - val_accuracy: 0.5781\n",
            "Epoch 176/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5304 - accuracy: 0.7812 - val_loss: 1.6845 - val_accuracy: 0.5437\n",
            "Epoch 177/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5456 - accuracy: 0.7594 - val_loss: 1.5182 - val_accuracy: 0.5469\n",
            "Epoch 178/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5301 - accuracy: 0.7734 - val_loss: 1.6597 - val_accuracy: 0.5750\n",
            "Epoch 179/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5330 - accuracy: 0.7812 - val_loss: 1.6029 - val_accuracy: 0.5406\n",
            "Epoch 180/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7578 - val_loss: 1.6213 - val_accuracy: 0.5406\n",
            "Epoch 181/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5184 - accuracy: 0.7680 - val_loss: 1.7162 - val_accuracy: 0.5344\n",
            "Epoch 182/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5079 - accuracy: 0.7867 - val_loss: 1.6459 - val_accuracy: 0.5938\n",
            "Epoch 183/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5193 - accuracy: 0.7828 - val_loss: 1.5950 - val_accuracy: 0.5469\n",
            "Epoch 184/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5508 - accuracy: 0.7625 - val_loss: 1.7722 - val_accuracy: 0.5406\n",
            "Epoch 185/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5542 - accuracy: 0.7516 - val_loss: 1.5612 - val_accuracy: 0.5625\n",
            "Epoch 186/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5753 - accuracy: 0.7625 - val_loss: 1.7298 - val_accuracy: 0.5625\n",
            "Epoch 187/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5632 - accuracy: 0.7656 - val_loss: 1.5375 - val_accuracy: 0.5406\n",
            "Epoch 188/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5367 - accuracy: 0.7750 - val_loss: 1.7399 - val_accuracy: 0.5594\n",
            "Epoch 189/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5095 - accuracy: 0.7633 - val_loss: 1.5064 - val_accuracy: 0.5500\n",
            "Epoch 190/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5531 - accuracy: 0.7609 - val_loss: 1.7226 - val_accuracy: 0.5562\n",
            "Epoch 191/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5151 - accuracy: 0.7773 - val_loss: 1.9226 - val_accuracy: 0.5406\n",
            "Epoch 192/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.8086 - val_loss: 1.7782 - val_accuracy: 0.5531\n",
            "Epoch 193/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5765 - accuracy: 0.7750 - val_loss: 1.6311 - val_accuracy: 0.5406\n",
            "Epoch 194/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7883 - val_loss: 1.8134 - val_accuracy: 0.5469\n",
            "Epoch 195/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7609 - val_loss: 1.7568 - val_accuracy: 0.5406\n",
            "Epoch 196/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7648 - val_loss: 1.7770 - val_accuracy: 0.5312\n",
            "Epoch 197/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5545 - accuracy: 0.7531 - val_loss: 1.6146 - val_accuracy: 0.5500\n",
            "Epoch 198/500\n",
            "40/40 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7711 - val_loss: 1.6186 - val_accuracy: 0.5656\n",
            "Epoch 199/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.7563 - val_loss: 1.6243 - val_accuracy: 0.5469\n",
            "Epoch 200/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5291 - accuracy: 0.7867 - val_loss: 1.6816 - val_accuracy: 0.5594\n",
            "Epoch 201/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7781 - val_loss: 1.8562 - val_accuracy: 0.5594\n",
            "Epoch 202/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.7984 - val_loss: 1.8734 - val_accuracy: 0.5406\n",
            "Epoch 203/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5425 - accuracy: 0.7719 - val_loss: 1.6484 - val_accuracy: 0.5500\n",
            "Epoch 204/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.7695 - val_loss: 1.7275 - val_accuracy: 0.5562\n",
            "Epoch 205/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4844 - accuracy: 0.7937 - val_loss: 1.9743 - val_accuracy: 0.5562\n",
            "Epoch 206/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7820 - val_loss: 2.1940 - val_accuracy: 0.5375\n",
            "Epoch 207/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.7891 - val_loss: 2.0249 - val_accuracy: 0.5500\n",
            "Epoch 208/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7961 - val_loss: 1.9462 - val_accuracy: 0.5656\n",
            "Epoch 209/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7922 - val_loss: 1.8288 - val_accuracy: 0.5562\n",
            "Epoch 210/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4882 - accuracy: 0.7852 - val_loss: 1.8039 - val_accuracy: 0.5562\n",
            "Epoch 211/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5055 - accuracy: 0.7859 - val_loss: 1.8636 - val_accuracy: 0.5312\n",
            "Epoch 212/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.7875 - val_loss: 1.8156 - val_accuracy: 0.5656\n",
            "Epoch 213/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4895 - accuracy: 0.7859 - val_loss: 1.9657 - val_accuracy: 0.5688\n",
            "Epoch 214/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5100 - accuracy: 0.7719 - val_loss: 1.8204 - val_accuracy: 0.5594\n",
            "Epoch 215/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.8086 - val_loss: 2.1591 - val_accuracy: 0.5531\n",
            "Epoch 216/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5010 - accuracy: 0.7891 - val_loss: 2.1560 - val_accuracy: 0.5188\n",
            "Epoch 217/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4720 - accuracy: 0.7914 - val_loss: 1.8699 - val_accuracy: 0.5531\n",
            "Epoch 218/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4968 - accuracy: 0.7922 - val_loss: 1.7554 - val_accuracy: 0.5875\n",
            "Epoch 219/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4518 - accuracy: 0.8273 - val_loss: 2.0580 - val_accuracy: 0.5531\n",
            "Epoch 220/500\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5028 - accuracy: 0.7828 - val_loss: 1.9663 - val_accuracy: 0.5344\n",
            "Epoch 221/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5396 - accuracy: 0.7563 - val_loss: 1.8859 - val_accuracy: 0.5625\n",
            "Epoch 222/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4640 - accuracy: 0.7891 - val_loss: 1.8426 - val_accuracy: 0.5625\n",
            "Epoch 223/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4860 - accuracy: 0.7891 - val_loss: 1.9017 - val_accuracy: 0.5344\n",
            "Epoch 224/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4693 - accuracy: 0.7922 - val_loss: 1.9928 - val_accuracy: 0.5531\n",
            "Epoch 225/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4656 - accuracy: 0.8008 - val_loss: 1.8549 - val_accuracy: 0.5656\n",
            "Epoch 226/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4780 - accuracy: 0.8055 - val_loss: 1.9383 - val_accuracy: 0.5344\n",
            "Epoch 227/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.7867 - val_loss: 1.9341 - val_accuracy: 0.5406\n",
            "Epoch 228/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.8000 - val_loss: 2.0270 - val_accuracy: 0.5656\n",
            "Epoch 229/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7914 - val_loss: 1.9098 - val_accuracy: 0.5594\n",
            "Epoch 230/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7688 - val_loss: 1.9080 - val_accuracy: 0.5469\n",
            "Epoch 231/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7875 - val_loss: 1.9360 - val_accuracy: 0.5500\n",
            "Epoch 232/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7812 - val_loss: 2.1229 - val_accuracy: 0.5344\n",
            "Epoch 233/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7750 - val_loss: 1.9164 - val_accuracy: 0.5406\n",
            "Epoch 234/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7914 - val_loss: 1.7972 - val_accuracy: 0.5156\n",
            "Epoch 235/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.7812 - val_loss: 2.0121 - val_accuracy: 0.5469\n",
            "Epoch 236/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7734 - val_loss: 2.0072 - val_accuracy: 0.5531\n",
            "Epoch 237/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5057 - accuracy: 0.7898 - val_loss: 1.8697 - val_accuracy: 0.5250\n",
            "Epoch 238/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5155 - accuracy: 0.7648 - val_loss: 1.9552 - val_accuracy: 0.5375\n",
            "Epoch 239/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5411 - accuracy: 0.7766 - val_loss: 1.7416 - val_accuracy: 0.5531\n",
            "Epoch 240/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5654 - accuracy: 0.7508 - val_loss: 1.7766 - val_accuracy: 0.5656\n",
            "Epoch 241/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5407 - accuracy: 0.7547 - val_loss: 1.9522 - val_accuracy: 0.5562\n",
            "Epoch 242/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5316 - accuracy: 0.7812 - val_loss: 2.0028 - val_accuracy: 0.5625\n",
            "Epoch 243/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7766 - val_loss: 2.0048 - val_accuracy: 0.5281\n",
            "Epoch 244/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7750 - val_loss: 2.0878 - val_accuracy: 0.5625\n",
            "Epoch 245/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.7922 - val_loss: 2.0537 - val_accuracy: 0.5656\n",
            "Epoch 246/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.7898 - val_loss: 1.9460 - val_accuracy: 0.5656\n",
            "Epoch 247/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7750 - val_loss: 2.1713 - val_accuracy: 0.5500\n",
            "Epoch 248/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5132 - accuracy: 0.7719 - val_loss: 2.1516 - val_accuracy: 0.5469\n",
            "Epoch 249/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7844 - val_loss: 2.0356 - val_accuracy: 0.5625\n",
            "Epoch 250/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.8055 - val_loss: 2.1208 - val_accuracy: 0.5625\n",
            "Epoch 251/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7937 - val_loss: 2.1237 - val_accuracy: 0.5625\n",
            "Epoch 252/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.7898 - val_loss: 2.2164 - val_accuracy: 0.5719\n",
            "Epoch 253/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.8031 - val_loss: 2.0961 - val_accuracy: 0.5594\n",
            "Epoch 254/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.7789 - val_loss: 2.1486 - val_accuracy: 0.5500\n",
            "Epoch 255/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.7828 - val_loss: 2.0924 - val_accuracy: 0.5781\n",
            "Epoch 256/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7742 - val_loss: 1.9805 - val_accuracy: 0.5750\n",
            "Epoch 257/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5144 - accuracy: 0.7766 - val_loss: 2.0252 - val_accuracy: 0.5688\n",
            "Epoch 258/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5021 - accuracy: 0.7828 - val_loss: 1.9566 - val_accuracy: 0.5562\n",
            "Epoch 259/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.7680 - val_loss: 1.9743 - val_accuracy: 0.5625\n",
            "Epoch 260/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5037 - accuracy: 0.7594 - val_loss: 2.1150 - val_accuracy: 0.5562\n",
            "Epoch 261/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7664 - val_loss: 2.2996 - val_accuracy: 0.5750\n",
            "Epoch 262/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7812 - val_loss: 2.2852 - val_accuracy: 0.5437\n",
            "Epoch 263/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7930 - val_loss: 2.2186 - val_accuracy: 0.5406\n",
            "Epoch 264/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.8109 - val_loss: 2.2114 - val_accuracy: 0.5594\n",
            "Epoch 265/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.7789 - val_loss: 2.0518 - val_accuracy: 0.5437\n",
            "Epoch 266/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7891 - val_loss: 2.1162 - val_accuracy: 0.5688\n",
            "Epoch 267/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.7937 - val_loss: 2.3341 - val_accuracy: 0.5375\n",
            "Epoch 268/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7914 - val_loss: 2.3416 - val_accuracy: 0.5344\n",
            "Epoch 269/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.8078 - val_loss: 2.0536 - val_accuracy: 0.5500\n",
            "Epoch 270/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4787 - accuracy: 0.7828 - val_loss: 2.0471 - val_accuracy: 0.5500\n",
            "Epoch 271/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.8062 - val_loss: 2.1773 - val_accuracy: 0.5375\n",
            "Epoch 272/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.8164 - val_loss: 2.3666 - val_accuracy: 0.5500\n",
            "Epoch 273/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8258 - val_loss: 2.3734 - val_accuracy: 0.5562\n",
            "Epoch 274/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.8008 - val_loss: 2.0088 - val_accuracy: 0.5531\n",
            "Epoch 275/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.8031 - val_loss: 2.4957 - val_accuracy: 0.5688\n",
            "Epoch 276/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8117 - val_loss: 2.3379 - val_accuracy: 0.5375\n",
            "Epoch 277/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8055 - val_loss: 2.1997 - val_accuracy: 0.5469\n",
            "Epoch 278/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4692 - accuracy: 0.7805 - val_loss: 2.3666 - val_accuracy: 0.5437\n",
            "Epoch 279/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.7945 - val_loss: 2.4782 - val_accuracy: 0.5625\n",
            "Epoch 280/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7922 - val_loss: 2.4413 - val_accuracy: 0.5625\n",
            "Epoch 281/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8133 - val_loss: 2.3002 - val_accuracy: 0.5469\n",
            "Epoch 282/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.8102 - val_loss: 2.1850 - val_accuracy: 0.5469\n",
            "Epoch 283/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4658 - accuracy: 0.7859 - val_loss: 2.1683 - val_accuracy: 0.5406\n",
            "Epoch 284/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5233 - accuracy: 0.7703 - val_loss: 1.9401 - val_accuracy: 0.5719\n",
            "Epoch 285/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.7680 - val_loss: 2.1172 - val_accuracy: 0.5531\n",
            "Epoch 286/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5559 - accuracy: 0.7641 - val_loss: 2.2924 - val_accuracy: 0.5375\n",
            "Epoch 287/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5137 - accuracy: 0.7734 - val_loss: 2.3539 - val_accuracy: 0.5437\n",
            "Epoch 288/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5084 - accuracy: 0.7828 - val_loss: 1.9756 - val_accuracy: 0.5437\n",
            "Epoch 289/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5312 - accuracy: 0.7648 - val_loss: 2.1555 - val_accuracy: 0.5312\n",
            "Epoch 290/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.8188 - val_loss: 2.3137 - val_accuracy: 0.5437\n",
            "Epoch 291/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4818 - accuracy: 0.7836 - val_loss: 2.3016 - val_accuracy: 0.5531\n",
            "Epoch 292/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4492 - accuracy: 0.8055 - val_loss: 2.3272 - val_accuracy: 0.5375\n",
            "Epoch 293/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5208 - accuracy: 0.7703 - val_loss: 2.1558 - val_accuracy: 0.5562\n",
            "Epoch 294/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5326 - accuracy: 0.7703 - val_loss: 2.0596 - val_accuracy: 0.5375\n",
            "Epoch 295/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5164 - accuracy: 0.7672 - val_loss: 2.3030 - val_accuracy: 0.5312\n",
            "Epoch 296/500\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4939 - accuracy: 0.7852 - val_loss: 2.2658 - val_accuracy: 0.5562\n",
            "Epoch 297/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4539 - accuracy: 0.8039 - val_loss: 2.6324 - val_accuracy: 0.5594\n",
            "Epoch 298/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4967 - accuracy: 0.7844 - val_loss: 2.4744 - val_accuracy: 0.5219\n",
            "Epoch 299/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5114 - accuracy: 0.7711 - val_loss: 2.2930 - val_accuracy: 0.5375\n",
            "Epoch 300/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.7812 - val_loss: 2.3701 - val_accuracy: 0.5625\n",
            "Epoch 301/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.8047 - val_loss: 2.3541 - val_accuracy: 0.5594\n",
            "Epoch 302/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.8188 - val_loss: 2.2787 - val_accuracy: 0.5469\n",
            "Epoch 303/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8148 - val_loss: 2.6951 - val_accuracy: 0.5250\n",
            "Epoch 304/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4000 - accuracy: 0.8281 - val_loss: 2.6512 - val_accuracy: 0.5281\n",
            "Epoch 305/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8367 - val_loss: 2.5169 - val_accuracy: 0.5562\n",
            "Epoch 306/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4210 - accuracy: 0.8195 - val_loss: 2.7847 - val_accuracy: 0.5500\n",
            "Epoch 307/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3917 - accuracy: 0.8313 - val_loss: 2.8599 - val_accuracy: 0.5531\n",
            "Epoch 308/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4034 - accuracy: 0.8320 - val_loss: 2.6798 - val_accuracy: 0.5469\n",
            "Epoch 309/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4064 - accuracy: 0.8305 - val_loss: 2.9132 - val_accuracy: 0.5406\n",
            "Epoch 310/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7953 - val_loss: 2.2841 - val_accuracy: 0.5406\n",
            "Epoch 311/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7906 - val_loss: 2.6159 - val_accuracy: 0.5312\n",
            "Epoch 312/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.8266 - val_loss: 2.4406 - val_accuracy: 0.5531\n",
            "Epoch 313/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3939 - accuracy: 0.8273 - val_loss: 2.7174 - val_accuracy: 0.5406\n",
            "Epoch 314/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8273 - val_loss: 2.8162 - val_accuracy: 0.5469\n",
            "Epoch 315/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3651 - accuracy: 0.8383 - val_loss: 2.5122 - val_accuracy: 0.5500\n",
            "Epoch 316/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8094 - val_loss: 2.6149 - val_accuracy: 0.5594\n",
            "Epoch 317/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.8055 - val_loss: 2.6396 - val_accuracy: 0.5469\n",
            "Epoch 318/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8039 - val_loss: 2.5571 - val_accuracy: 0.5500\n",
            "Epoch 319/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.7875 - val_loss: 2.6656 - val_accuracy: 0.5719\n",
            "Epoch 320/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.8055 - val_loss: 2.4342 - val_accuracy: 0.5562\n",
            "Epoch 321/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4963 - accuracy: 0.7844 - val_loss: 2.3983 - val_accuracy: 0.5125\n",
            "Epoch 322/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4375 - accuracy: 0.7977 - val_loss: 2.5386 - val_accuracy: 0.5625\n",
            "Epoch 323/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8156 - val_loss: 2.6358 - val_accuracy: 0.5500\n",
            "Epoch 324/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.8016 - val_loss: 2.8356 - val_accuracy: 0.5437\n",
            "Epoch 325/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.8086 - val_loss: 2.6114 - val_accuracy: 0.5562\n",
            "Epoch 326/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4861 - accuracy: 0.7969 - val_loss: 2.2897 - val_accuracy: 0.5406\n",
            "Epoch 327/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.8094 - val_loss: 2.6006 - val_accuracy: 0.5406\n",
            "Epoch 328/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8195 - val_loss: 2.6300 - val_accuracy: 0.5562\n",
            "Epoch 329/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.8078 - val_loss: 2.3322 - val_accuracy: 0.5437\n",
            "Epoch 330/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.8062 - val_loss: 2.5959 - val_accuracy: 0.5344\n",
            "Epoch 331/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7953 - val_loss: 2.8143 - val_accuracy: 0.5375\n",
            "Epoch 332/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4775 - accuracy: 0.7984 - val_loss: 2.4601 - val_accuracy: 0.5469\n",
            "Epoch 333/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.8195 - val_loss: 2.4682 - val_accuracy: 0.5250\n",
            "Epoch 334/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3989 - accuracy: 0.8406 - val_loss: 2.8880 - val_accuracy: 0.5406\n",
            "Epoch 335/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.8062 - val_loss: 2.8586 - val_accuracy: 0.5437\n",
            "Epoch 336/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3932 - accuracy: 0.8164 - val_loss: 3.1902 - val_accuracy: 0.5312\n",
            "Epoch 337/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3771 - accuracy: 0.8313 - val_loss: 3.0295 - val_accuracy: 0.5406\n",
            "Epoch 338/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4032 - accuracy: 0.8313 - val_loss: 2.9522 - val_accuracy: 0.5406\n",
            "Epoch 339/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3862 - accuracy: 0.8320 - val_loss: 2.5828 - val_accuracy: 0.5406\n",
            "Epoch 340/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.8070 - val_loss: 2.8201 - val_accuracy: 0.5312\n",
            "Epoch 341/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8398 - val_loss: 2.7359 - val_accuracy: 0.5469\n",
            "Epoch 342/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4140 - accuracy: 0.8156 - val_loss: 2.8106 - val_accuracy: 0.5406\n",
            "Epoch 343/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.8273 - val_loss: 2.8360 - val_accuracy: 0.5375\n",
            "Epoch 344/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8234 - val_loss: 2.6612 - val_accuracy: 0.5625\n",
            "Epoch 345/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.8070 - val_loss: 2.4888 - val_accuracy: 0.5594\n",
            "Epoch 346/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.7992 - val_loss: 2.6627 - val_accuracy: 0.5500\n",
            "Epoch 347/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7844 - val_loss: 2.6739 - val_accuracy: 0.5500\n",
            "Epoch 348/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7977 - val_loss: 2.6824 - val_accuracy: 0.5594\n",
            "Epoch 349/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.8086 - val_loss: 2.6803 - val_accuracy: 0.5406\n",
            "Epoch 350/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4254 - accuracy: 0.8219 - val_loss: 2.7306 - val_accuracy: 0.5344\n",
            "Epoch 351/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7961 - val_loss: 2.6090 - val_accuracy: 0.5312\n",
            "Epoch 352/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8180 - val_loss: 2.9796 - val_accuracy: 0.5500\n",
            "Epoch 353/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4009 - accuracy: 0.8313 - val_loss: 2.6743 - val_accuracy: 0.5500\n",
            "Epoch 354/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4048 - accuracy: 0.8281 - val_loss: 3.2008 - val_accuracy: 0.5594\n",
            "Epoch 355/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3993 - accuracy: 0.8148 - val_loss: 3.0099 - val_accuracy: 0.5406\n",
            "Epoch 356/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3880 - accuracy: 0.8250 - val_loss: 2.8113 - val_accuracy: 0.5312\n",
            "Epoch 357/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8219 - val_loss: 2.6715 - val_accuracy: 0.5250\n",
            "Epoch 358/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.7945 - val_loss: 2.7423 - val_accuracy: 0.5312\n",
            "Epoch 359/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5006 - accuracy: 0.7930 - val_loss: 2.5818 - val_accuracy: 0.5250\n",
            "Epoch 360/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4473 - accuracy: 0.8094 - val_loss: 2.6442 - val_accuracy: 0.5375\n",
            "Epoch 361/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.8023 - val_loss: 2.4460 - val_accuracy: 0.5312\n",
            "Epoch 362/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5097 - accuracy: 0.7883 - val_loss: 2.4814 - val_accuracy: 0.5437\n",
            "Epoch 363/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4925 - accuracy: 0.7758 - val_loss: 2.6909 - val_accuracy: 0.5469\n",
            "Epoch 364/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4793 - accuracy: 0.7906 - val_loss: 2.5678 - val_accuracy: 0.5188\n",
            "Epoch 365/500\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4463 - accuracy: 0.8023 - val_loss: 2.7214 - val_accuracy: 0.5344\n",
            "Epoch 366/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4163 - accuracy: 0.8133 - val_loss: 2.4437 - val_accuracy: 0.5344\n",
            "Epoch 367/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4600 - accuracy: 0.8008 - val_loss: 2.6026 - val_accuracy: 0.5281\n",
            "Epoch 368/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.8156 - val_loss: 2.6233 - val_accuracy: 0.5406\n",
            "Epoch 369/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4427 - accuracy: 0.8188 - val_loss: 2.6158 - val_accuracy: 0.5625\n",
            "Epoch 370/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4171 - accuracy: 0.8258 - val_loss: 2.8337 - val_accuracy: 0.5469\n",
            "Epoch 371/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4558 - accuracy: 0.8086 - val_loss: 2.5836 - val_accuracy: 0.5437\n",
            "Epoch 372/500\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4709 - accuracy: 0.7961 - val_loss: 2.8866 - val_accuracy: 0.5406\n",
            "Epoch 373/500\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4738 - accuracy: 0.7977 - val_loss: 2.4248 - val_accuracy: 0.5375\n",
            "Epoch 374/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4767 - accuracy: 0.7977 - val_loss: 2.6490 - val_accuracy: 0.5281\n",
            "Epoch 375/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8062 - val_loss: 2.8818 - val_accuracy: 0.5219\n",
            "Epoch 376/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.8078 - val_loss: 2.5964 - val_accuracy: 0.5312\n",
            "Epoch 377/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.8078 - val_loss: 2.8469 - val_accuracy: 0.5281\n",
            "Epoch 378/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7680 - val_loss: 2.5777 - val_accuracy: 0.5437\n",
            "Epoch 379/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7773 - val_loss: 2.5531 - val_accuracy: 0.5406\n",
            "Epoch 380/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7930 - val_loss: 2.5931 - val_accuracy: 0.5344\n",
            "Epoch 381/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.7797 - val_loss: 2.4429 - val_accuracy: 0.5437\n",
            "Epoch 382/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4786 - accuracy: 0.7891 - val_loss: 2.6540 - val_accuracy: 0.5281\n",
            "Epoch 383/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.8031 - val_loss: 3.1565 - val_accuracy: 0.5250\n",
            "Epoch 384/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.8023 - val_loss: 2.7003 - val_accuracy: 0.5594\n",
            "Epoch 385/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.8102 - val_loss: 3.0464 - val_accuracy: 0.5312\n",
            "Epoch 386/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4095 - accuracy: 0.8133 - val_loss: 2.5759 - val_accuracy: 0.5437\n",
            "Epoch 387/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8133 - val_loss: 3.3550 - val_accuracy: 0.5188\n",
            "Epoch 388/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.8109 - val_loss: 2.6355 - val_accuracy: 0.5312\n",
            "Epoch 389/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4852 - accuracy: 0.7766 - val_loss: 2.8329 - val_accuracy: 0.5500\n",
            "Epoch 390/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.7906 - val_loss: 2.4600 - val_accuracy: 0.5281\n",
            "Epoch 391/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4996 - accuracy: 0.7883 - val_loss: 2.2788 - val_accuracy: 0.5594\n",
            "Epoch 392/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7945 - val_loss: 2.8163 - val_accuracy: 0.5344\n",
            "Epoch 393/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.7992 - val_loss: 2.4991 - val_accuracy: 0.5281\n",
            "Epoch 394/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.8188 - val_loss: 2.7450 - val_accuracy: 0.5562\n",
            "Epoch 395/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.8070 - val_loss: 2.4372 - val_accuracy: 0.5625\n",
            "Epoch 396/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.8016 - val_loss: 2.8006 - val_accuracy: 0.5469\n",
            "Epoch 397/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7750 - val_loss: 2.6443 - val_accuracy: 0.5625\n",
            "Epoch 398/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7969 - val_loss: 2.7827 - val_accuracy: 0.5344\n",
            "Epoch 399/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7984 - val_loss: 2.5897 - val_accuracy: 0.5281\n",
            "Epoch 400/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.8141 - val_loss: 2.5958 - val_accuracy: 0.5562\n",
            "Epoch 401/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4593 - accuracy: 0.8047 - val_loss: 2.6759 - val_accuracy: 0.5625\n",
            "Epoch 402/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7883 - val_loss: 2.8079 - val_accuracy: 0.5437\n",
            "Epoch 403/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.8039 - val_loss: 2.9332 - val_accuracy: 0.5312\n",
            "Epoch 404/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8250 - val_loss: 3.2067 - val_accuracy: 0.5281\n",
            "Epoch 405/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8156 - val_loss: 2.8398 - val_accuracy: 0.5406\n",
            "Epoch 406/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.8203 - val_loss: 3.1307 - val_accuracy: 0.5437\n",
            "Epoch 407/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4110 - accuracy: 0.8281 - val_loss: 2.9991 - val_accuracy: 0.5437\n",
            "Epoch 408/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4256 - accuracy: 0.8164 - val_loss: 3.0387 - val_accuracy: 0.5312\n",
            "Epoch 409/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4717 - accuracy: 0.7937 - val_loss: 3.2409 - val_accuracy: 0.5531\n",
            "Epoch 410/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.8078 - val_loss: 2.9866 - val_accuracy: 0.5375\n",
            "Epoch 411/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.8070 - val_loss: 2.7292 - val_accuracy: 0.5344\n",
            "Epoch 412/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4942 - accuracy: 0.7875 - val_loss: 2.8442 - val_accuracy: 0.5250\n",
            "Epoch 413/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.8094 - val_loss: 2.8698 - val_accuracy: 0.5469\n",
            "Epoch 414/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4005 - accuracy: 0.8148 - val_loss: 3.2209 - val_accuracy: 0.5344\n",
            "Epoch 415/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.7992 - val_loss: 2.6573 - val_accuracy: 0.5531\n",
            "Epoch 416/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.7984 - val_loss: 2.9338 - val_accuracy: 0.5562\n",
            "Epoch 417/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7922 - val_loss: 2.9465 - val_accuracy: 0.5312\n",
            "Epoch 418/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.7930 - val_loss: 2.9481 - val_accuracy: 0.5469\n",
            "Epoch 419/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8062 - val_loss: 2.6900 - val_accuracy: 0.5531\n",
            "Epoch 420/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.7898 - val_loss: 2.8553 - val_accuracy: 0.5594\n",
            "Epoch 421/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.8000 - val_loss: 2.7887 - val_accuracy: 0.5562\n",
            "Epoch 422/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4359 - accuracy: 0.8086 - val_loss: 2.5754 - val_accuracy: 0.5719\n",
            "Epoch 423/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7922 - val_loss: 2.6742 - val_accuracy: 0.5406\n",
            "Epoch 424/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7648 - val_loss: 2.9146 - val_accuracy: 0.5531\n",
            "Epoch 425/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.8109 - val_loss: 3.0897 - val_accuracy: 0.5469\n",
            "Epoch 426/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7852 - val_loss: 3.1215 - val_accuracy: 0.5500\n",
            "Epoch 427/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.8078 - val_loss: 3.0235 - val_accuracy: 0.5500\n",
            "Epoch 428/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8023 - val_loss: 3.2832 - val_accuracy: 0.5562\n",
            "Epoch 429/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8133 - val_loss: 3.0898 - val_accuracy: 0.5688\n",
            "Epoch 430/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.7914 - val_loss: 2.7569 - val_accuracy: 0.5375\n",
            "Epoch 431/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.5173 - accuracy: 0.7680 - val_loss: 2.6907 - val_accuracy: 0.5562\n",
            "Epoch 432/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5052 - accuracy: 0.7781 - val_loss: 2.6217 - val_accuracy: 0.5562\n",
            "Epoch 433/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4684 - accuracy: 0.7875 - val_loss: 3.0291 - val_accuracy: 0.5500\n",
            "Epoch 434/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4307 - accuracy: 0.8055 - val_loss: 3.0109 - val_accuracy: 0.5625\n",
            "Epoch 435/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4532 - accuracy: 0.8000 - val_loss: 3.1246 - val_accuracy: 0.5469\n",
            "Epoch 436/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.8141 - val_loss: 2.8597 - val_accuracy: 0.5406\n",
            "Epoch 437/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4181 - accuracy: 0.8156 - val_loss: 2.9758 - val_accuracy: 0.5500\n",
            "Epoch 438/500\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.4072 - accuracy: 0.8086 - val_loss: 3.1315 - val_accuracy: 0.5594\n",
            "Epoch 439/500\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5218 - accuracy: 0.7688 - val_loss: 3.0099 - val_accuracy: 0.5156\n",
            "Epoch 440/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4717 - accuracy: 0.7961 - val_loss: 2.7409 - val_accuracy: 0.5531\n",
            "Epoch 441/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.5161 - accuracy: 0.7664 - val_loss: 2.9322 - val_accuracy: 0.5344\n",
            "Epoch 442/500\n",
            "40/40 [==============================] - 0s 8ms/step - loss: 0.5230 - accuracy: 0.7656 - val_loss: 2.6498 - val_accuracy: 0.5375\n",
            "Epoch 443/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4634 - accuracy: 0.7875 - val_loss: 3.1728 - val_accuracy: 0.5531\n",
            "Epoch 444/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4261 - accuracy: 0.8164 - val_loss: 3.3563 - val_accuracy: 0.5437\n",
            "Epoch 445/500\n",
            "40/40 [==============================] - 0s 7ms/step - loss: 0.4459 - accuracy: 0.8008 - val_loss: 3.1940 - val_accuracy: 0.5531\n",
            "Epoch 446/500\n",
            "40/40 [==============================] - 0s 6ms/step - loss: 0.4153 - accuracy: 0.8094 - val_loss: 3.1677 - val_accuracy: 0.5469\n",
            "Epoch 447/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4067 - accuracy: 0.8281 - val_loss: 3.3457 - val_accuracy: 0.5625\n",
            "Epoch 448/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3739 - accuracy: 0.8242 - val_loss: 3.0543 - val_accuracy: 0.5562\n",
            "Epoch 449/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3998 - accuracy: 0.8156 - val_loss: 2.8110 - val_accuracy: 0.5250\n",
            "Epoch 450/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8227 - val_loss: 2.9889 - val_accuracy: 0.5469\n",
            "Epoch 451/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8242 - val_loss: 3.3083 - val_accuracy: 0.5344\n",
            "Epoch 452/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.7898 - val_loss: 3.1609 - val_accuracy: 0.5406\n",
            "Epoch 453/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8039 - val_loss: 3.4857 - val_accuracy: 0.5688\n",
            "Epoch 454/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.8219 - val_loss: 3.2714 - val_accuracy: 0.5437\n",
            "Epoch 455/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7945 - val_loss: 2.7337 - val_accuracy: 0.5500\n",
            "Epoch 456/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4573 - accuracy: 0.7898 - val_loss: 3.2240 - val_accuracy: 0.5531\n",
            "Epoch 457/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4959 - accuracy: 0.7945 - val_loss: 2.6829 - val_accuracy: 0.5406\n",
            "Epoch 458/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5227 - accuracy: 0.7758 - val_loss: 2.5824 - val_accuracy: 0.5281\n",
            "Epoch 459/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.7984 - val_loss: 2.8267 - val_accuracy: 0.5188\n",
            "Epoch 460/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7711 - val_loss: 3.0156 - val_accuracy: 0.5281\n",
            "Epoch 461/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4132 - accuracy: 0.8156 - val_loss: 3.4559 - val_accuracy: 0.5281\n",
            "Epoch 462/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4557 - accuracy: 0.8078 - val_loss: 2.9156 - val_accuracy: 0.5219\n",
            "Epoch 463/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8141 - val_loss: 2.7644 - val_accuracy: 0.5406\n",
            "Epoch 464/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4753 - accuracy: 0.7906 - val_loss: 3.2178 - val_accuracy: 0.5344\n",
            "Epoch 465/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.5130 - accuracy: 0.7789 - val_loss: 3.0068 - val_accuracy: 0.5312\n",
            "Epoch 466/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4122 - accuracy: 0.8234 - val_loss: 3.3337 - val_accuracy: 0.5594\n",
            "Epoch 467/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4031 - accuracy: 0.8148 - val_loss: 3.5059 - val_accuracy: 0.5375\n",
            "Epoch 468/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8141 - val_loss: 3.0676 - val_accuracy: 0.5594\n",
            "Epoch 469/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3962 - accuracy: 0.8211 - val_loss: 3.1076 - val_accuracy: 0.5531\n",
            "Epoch 470/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8234 - val_loss: 3.6925 - val_accuracy: 0.5375\n",
            "Epoch 471/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.8367 - val_loss: 3.5618 - val_accuracy: 0.5344\n",
            "Epoch 472/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8219 - val_loss: 3.1839 - val_accuracy: 0.5469\n",
            "Epoch 473/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.8109 - val_loss: 3.1272 - val_accuracy: 0.5125\n",
            "Epoch 474/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4682 - accuracy: 0.7953 - val_loss: 3.1615 - val_accuracy: 0.5375\n",
            "Epoch 475/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.8023 - val_loss: 3.1447 - val_accuracy: 0.5562\n",
            "Epoch 476/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4542 - accuracy: 0.7961 - val_loss: 3.5335 - val_accuracy: 0.5500\n",
            "Epoch 477/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7836 - val_loss: 3.1940 - val_accuracy: 0.5406\n",
            "Epoch 478/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4989 - accuracy: 0.7773 - val_loss: 3.0084 - val_accuracy: 0.5375\n",
            "Epoch 479/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.8062 - val_loss: 2.7065 - val_accuracy: 0.5406\n",
            "Epoch 480/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8070 - val_loss: 3.3115 - val_accuracy: 0.5469\n",
            "Epoch 481/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8172 - val_loss: 3.1433 - val_accuracy: 0.5406\n",
            "Epoch 482/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3934 - accuracy: 0.8195 - val_loss: 3.4119 - val_accuracy: 0.5344\n",
            "Epoch 483/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3865 - accuracy: 0.8297 - val_loss: 3.4094 - val_accuracy: 0.5188\n",
            "Epoch 484/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3658 - accuracy: 0.8438 - val_loss: 4.0785 - val_accuracy: 0.5312\n",
            "Epoch 485/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4188 - accuracy: 0.8195 - val_loss: 3.1943 - val_accuracy: 0.5531\n",
            "Epoch 486/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4017 - accuracy: 0.8164 - val_loss: 3.6959 - val_accuracy: 0.5250\n",
            "Epoch 487/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3907 - accuracy: 0.8383 - val_loss: 3.8884 - val_accuracy: 0.5344\n",
            "Epoch 488/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3849 - accuracy: 0.8250 - val_loss: 3.5958 - val_accuracy: 0.5250\n",
            "Epoch 489/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4072 - accuracy: 0.8164 - val_loss: 3.6028 - val_accuracy: 0.5188\n",
            "Epoch 490/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3987 - accuracy: 0.8227 - val_loss: 3.7071 - val_accuracy: 0.5281\n",
            "Epoch 491/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4056 - accuracy: 0.8125 - val_loss: 3.3717 - val_accuracy: 0.5312\n",
            "Epoch 492/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3921 - accuracy: 0.8250 - val_loss: 3.3332 - val_accuracy: 0.5562\n",
            "Epoch 493/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.8305 - val_loss: 3.4381 - val_accuracy: 0.5375\n",
            "Epoch 494/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.8148 - val_loss: 3.8768 - val_accuracy: 0.5312\n",
            "Epoch 495/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4142 - accuracy: 0.8117 - val_loss: 3.6863 - val_accuracy: 0.5406\n",
            "Epoch 496/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8164 - val_loss: 3.8273 - val_accuracy: 0.5219\n",
            "Epoch 497/500\n",
            "40/40 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.8242 - val_loss: 3.4777 - val_accuracy: 0.5312\n",
            "Epoch 498/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.3801 - accuracy: 0.8484 - val_loss: 3.4244 - val_accuracy: 0.5312\n",
            "Epoch 499/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4130 - accuracy: 0.8227 - val_loss: 3.1199 - val_accuracy: 0.5500\n",
            "Epoch 500/500\n",
            "40/40 [==============================] - 0s 4ms/step - loss: 0.4115 - accuracy: 0.8273 - val_loss: 3.3525 - val_accuracy: 0.5156\n",
            "[[2.9364909e-15 8.3118081e-05 9.9804318e-01 1.8736353e-03 8.6113447e-18\n",
            "  1.2090809e-28]\n",
            " [6.0181116e-04 1.2255444e-01 8.7650871e-01 3.3514228e-04 6.2768128e-09\n",
            "  1.7486372e-11]\n",
            " [2.8073872e-04 2.0009577e-02 9.7690874e-01 2.8007701e-03 1.2116924e-07\n",
            "  3.3673894e-10]\n",
            " ...\n",
            " [4.4018620e-06 4.8915854e-01 5.1083708e-01 4.0896379e-17 2.6185643e-30\n",
            "  2.9962890e-34]\n",
            " [8.3730221e-05 9.9991632e-01 5.6898073e-11 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00]\n",
            " [4.1841386e-06 7.5076771e-04 6.9020951e-01 3.0902112e-01 1.4444800e-05\n",
            "  3.3299277e-09]]\n",
            "[[4.10772039e-08 2.72374153e-01 7.27625787e-01 2.53668908e-09\n",
            "  7.68676487e-21 1.15937008e-26]\n",
            " [5.69384695e-15 1.77425946e-07 9.04903173e-01 9.50965807e-02\n",
            "  1.11964535e-13 2.17378227e-23]\n",
            " [2.44086448e-04 1.07957756e-04 5.75871348e-01 4.19883698e-01\n",
            "  3.83697893e-03 5.58513530e-05]\n",
            " ...\n",
            " [2.50693737e-12 6.23066703e-23 6.94252902e-12 5.26661813e-01\n",
            "  4.17304158e-01 5.60340732e-02]\n",
            " [1.31537490e-07 1.56002074e-01 8.25105965e-01 1.88918207e-02\n",
            "  4.70565031e-10 7.44412365e-16]\n",
            " [1.34900825e-12 1.51019263e-23 4.52921277e-11 5.90088546e-01\n",
            "  3.70991588e-01 3.89197804e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert probabilities to class predictions\n",
        "y_train_pred_classes = np.argmax(y_train_pred, axis=1)\n",
        "y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
        "\n",
        "print(y_train_pred_classes)\n",
        "print(y_test_pred_classes)\n",
        "print(y)\n",
        "print(y_one_hot_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qq-05zXGq5x",
        "outputId": "e1f420d1-640a-4553-d44d-08ab8828c588"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 2 ... 2 1 2]\n",
            "[2 2 2 1 1 2 1 2 1 3 1 1 1 2 2 3 1 2 3 1 0 1 2 0 1 3 1 2 1 1 2 3 2 2 1 2 1\n",
            " 1 2 3 1 3 1 2 2 2 2 3 3 2 3 3 2 2 1 3 3 1 1 1 2 2 2 3 2 1 2 1 3 1 3 1 2 1\n",
            " 3 1 1 2 0 3 2 4 1 2 1 1 3 1 2 1 3 3 1 2 1 1 0 2 1 1 1 2 0 1 1 2 4 2 2 2 1\n",
            " 3 1 3 1 2 3 2 3 0 2 2 2 1 2 2 1 3 1 2 1 2 2 2 2 1 1 4 2 2 1 1 2 0 2 2 0 0\n",
            " 2 2 1 1 1 2 3 1 3 3 1 2 1 1 1 2 2 1 3 3 2 1 1 2 3 2 2 3 2 2 3 3 4 2 3 2 3\n",
            " 1 1 1 3 3 1 3 2 3 1 4 1 2 1 1 2 1 3 2 2 2 2 3 1 2 4 3 2 2 2 4 1 2 4 1 1 2\n",
            " 3 1 2 1 2 1 1 3 1 3 3 3 2 3 2 2 2 2 2 2 3 2 2 1 1 2 1 2 0 3 1 3 1 2 0 2 3\n",
            " 2 2 1 1 3 4 1 3 1 2 3 3 2 1 2 1 1 1 1 2 2 3 3 1 1 2 2 1 1 2 2 1 1 1 1 2 2\n",
            " 3 1 2 2 0 2 1 2 2 2 1 1 3 2 2 2 3 4 3 1 1 3 2 1 1 3 1 1 3 3 1 3 1 4 3 1 2\n",
            " 2 1 2 1 0 1 2 2 2 1 1 2 3 2 1 0 2 1 2 2 1 2 2 2 2 1 3 2 1 2 3 0 1 1 0 2 2\n",
            " 2 1 2 1 1 2 3 1 2 2 0 1 2 1 3 1 2 2 1 1 2 1 2 0 2 1 2 3 2 3]\n",
            "[3 3 4 ... 4 2 3]\n",
            "[[0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we were confirming that the data was decoded correctly. When the data is encoded, it's hard to know exactly what is going on."
      ],
      "metadata": {
        "id": "_pA4i2KJggPz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert integer labels to original categories\n",
        "predicted_categories_train = label_encoder.inverse_transform(y_train_pred_classes)\n",
        "predicted_categories_test = label_encoder.inverse_transform(y_test_pred_classes)\n",
        "print(predicted_categories_train)\n",
        "print(predicted_categories_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li_WWJkFcEbs",
        "outputId": "1b8bf3db-c37d-4006-faba-4b82a2cf3631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 3 3 ... 3 2 3]\n",
            "[3 3 3 2 2 3 2 3 2 4 2 2 2 3 3 4 2 3 4 2 1 2 3 1 2 4 2 3 2 2 3 4 3 3 2 3 2\n",
            " 2 3 4 2 4 2 3 3 3 3 4 4 3 4 4 3 3 2 4 4 2 2 2 3 3 3 4 3 2 3 2 4 2 4 2 3 2\n",
            " 4 2 2 3 1 4 3 5 2 3 2 2 4 2 3 2 4 4 2 3 2 2 1 3 2 2 2 3 1 2 2 3 5 3 3 3 2\n",
            " 4 2 4 2 3 4 3 4 1 3 3 3 2 3 3 2 4 2 3 2 3 3 3 3 2 2 5 3 3 2 2 3 1 3 3 1 1\n",
            " 3 3 2 2 2 3 4 2 4 4 2 3 2 2 2 3 3 2 4 4 3 2 2 3 4 3 3 4 3 3 4 4 5 3 4 3 4\n",
            " 2 2 2 4 4 2 4 3 4 2 5 2 3 2 2 3 2 4 3 3 3 3 4 2 3 5 4 3 3 3 5 2 3 5 2 2 3\n",
            " 4 2 3 2 3 2 2 4 2 4 4 4 3 4 3 3 3 3 3 3 4 3 3 2 2 3 2 3 1 4 2 4 2 3 1 3 4\n",
            " 3 3 2 2 4 5 2 4 2 3 4 4 3 2 3 2 2 2 2 3 3 4 4 2 2 3 3 2 2 3 3 2 2 2 2 3 3\n",
            " 4 2 3 3 1 3 2 3 3 3 2 2 4 3 3 3 4 5 4 2 2 4 3 2 2 4 2 2 4 4 2 4 2 5 4 2 3\n",
            " 3 2 3 2 1 2 3 3 3 2 2 3 4 3 2 1 3 2 3 3 2 3 3 3 3 2 4 3 2 3 4 1 2 2 1 3 3\n",
            " 3 2 3 2 2 3 4 2 3 3 1 2 3 2 4 2 3 3 2 2 3 2 3 1 3 2 3 4 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "train_accuracy = accuracy_score(np.argmax(y_train, axis=1), y_train_pred_classes)\n",
        "test_accuracy = accuracy_score(np.argmax(y_test, axis=1), y_test_pred_classes)\n",
        "\n",
        "print(\"Train Accuracy:\", train_accuracy)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsJauV0qHT_3",
        "outputId": "7a0f1fd8-79e5-4ab6-a9dc-d278390397de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.845625\n",
            "Test Accuracy: 0.5225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This data looks good."
      ],
      "metadata": {
        "id": "4oY2FoqV4bge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Evaluation"
      ],
      "metadata": {
        "id": "8XNqSraYAIPm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDdGAzOfLWgz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "9334f70b-e8b3-493d-9bf5-35f5438bfd18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 3ms/step - loss: 3.0075 - accuracy: 0.5225\n",
            "Test Loss: 3.0075409412384033\n",
            "Test Accuracy: 0.5224999785423279\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Loss: {test_loss}')\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "\n",
        "# Plot the training and validation accuracy/loss over epochs\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A plot that looks like this is a reasonable training scheme. The loss has a minimum which means that there is an optimal training timesclae to prevent overfitting. The X axis the amount of training and there seems to be a training sweetspot (more epoch is more training) too many epochs = overfitting."
      ],
      "metadata": {
        "id": "kWFvkjJqgyMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "|"
      ],
      "metadata": {
        "id": "v_wVITEOk8e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "1e4e6ad7-c8c2-4f68-b4bb-d397ca4fce77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-31-4b37ef281455>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-31-4b37ef281455>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    |\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proof of concept practice/extra code"
      ],
      "metadata": {
        "id": "gHEyBkNmUsp3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#X_bow_array_df = pd.DataFrame(X_bow_array)\n",
        "#X_bow_array_df\n",
        "#value_summary = X_bow_array_df['Value'].describe()\n",
        "#print(value_summary)"
      ],
      "metadata": {
        "id": "fTqWKy3Ak8bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index in random_indices:\n",
        "    print(\"Row Index:\", index)\n",
        "    print(\"\\nPreprocessed Text:\")\n",
        "    print(essay_df.loc[index, 'preprocessed'])\n",
        "    print(\"\\nBOWVector dictionary:\")\n",
        "    print(essay_df.loc[index, 'BOWVector'])\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")  # Add a separator between rows"
      ],
      "metadata": {
        "id": "ZQhCyKiGVTwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "essay = \"The Quick 10% of two 1,000 Foxes, Jumped! can't 1.00 won't wouldn't : would've I'm she's. 1982 (044). well-being model -T position-estimating\""
      ],
      "metadata": {
        "id": "Bgf6c0xdUvmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "essay = essay.replace(\"-\", \" \")\n",
        "essay = essay.replace(\"%\", \" percent \")"
      ],
      "metadata": {
        "id": "tY7aJASsUvxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "essay_expanded = contractions.fix(essay)\n",
        "essay_expanded"
      ],
      "metadata": {
        "id": "lPD2gLu_Uv0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(essay_expanded) # just splitting on spaces\n",
        "tokens"
      ],
      "metadata": {
        "id": "590mpYmQUv4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def contains_numeric(token):\n",
        "    return any(char.isdigit() for char in token)\n",
        "\n",
        "def convert_numbers_to_words(token):\n",
        "    if contains_numeric(token):\n",
        "        # Remove any punctuation from the token before conversion\n",
        "        token = re.sub(r'[^\\w\\s.]', '', token)\n",
        "\n",
        "        wordString = p.number_to_words(token)\n",
        "\n",
        "        wordString = wordString.replace(\"-\", \" \")\n",
        "\n",
        "        # Tokenize the wordString\n",
        "        tokens = word_tokenize(wordString)\n",
        "\n",
        "        return tokens  # Return the flat list of tokens instead of a list of lists\n",
        "    else:\n",
        "        return [token]  # Return the token as a list"
      ],
      "metadata": {
        "id": "IJcs5SU3U7vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "processedTokens = []\n",
        "\n",
        "for token in tokens:\n",
        "    processedTokens.extend(convert_numbers_to_words(token))\n",
        "\n",
        "processedTokens"
      ],
      "metadata": {
        "id": "bqXuQuclU73W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuation and convert to lowercase\n",
        "essayTokens = [word.lower() for word in processedTokens if word.isalpha()]\n",
        "essayTokens"
      ],
      "metadata": {
        "id": "S_DC1gvuU76U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, remove stopwords (common words like 'the', 'and', etc.)\n",
        "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
        "essayTokensClean = [word for word in essayTokens if word not in stop_words]\n",
        "essayTokensClean"
      ],
      "metadata": {
        "id": "goBbQBMJU79T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other options before vectorizing: stemming, lemmatization, stop words (which we already did), other types of token manipulations (might include context), spelling consideration..."
      ],
      "metadata": {
        "id": "QlVPVk7dVESF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VECTORIZE!\n",
        "\n",
        "bowRepresentation = Counter(essayTokensClean)\n",
        "bowRepresentation"
      ],
      "metadata": {
        "id": "2dX3wbDKU7_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "essay2 = \"The Quick 10% of two 1,000 Foxes, Jumped! can't 1.00 won't wouldn't : would've I'm she's. 1982 (044). well-being model -T position-estimating\""
      ],
      "metadata": {
        "id": "1ucnue81VHAb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4812187f46a240f7be791e7a6a525ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ad85d6d62d246bb8781df496b708d56",
              "IPY_MODEL_e14c42796dcf4862af5b918a241acfe7",
              "IPY_MODEL_22bd7fac00e14f258be333c0a79a4625"
            ],
            "layout": "IPY_MODEL_644c6adafbf7480aa703ad260c716a63"
          }
        },
        "6ad85d6d62d246bb8781df496b708d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d049a356417406d9b29543940fa3ec7",
            "placeholder": "​",
            "style": "IPY_MODEL_c0fb7c7a1bab4503b4a3a6f41031abd4",
            "value": "Downloading: 100%"
          }
        },
        "e14c42796dcf4862af5b918a241acfe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21aff9822ac3460ca4b5a80ce2293d4f",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82a6dced54664ad680d0fa1e1a907553",
            "value": 231508
          }
        },
        "22bd7fac00e14f258be333c0a79a4625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0efe287dd0a4fb3a71bc8bc7d710f42",
            "placeholder": "​",
            "style": "IPY_MODEL_d664b0dc951f4771b27cb462208ee1c2",
            "value": " 226k/226k [00:00&lt;00:00, 1.28MB/s]"
          }
        },
        "644c6adafbf7480aa703ad260c716a63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d049a356417406d9b29543940fa3ec7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0fb7c7a1bab4503b4a3a6f41031abd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21aff9822ac3460ca4b5a80ce2293d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82a6dced54664ad680d0fa1e1a907553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0efe287dd0a4fb3a71bc8bc7d710f42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d664b0dc951f4771b27cb462208ee1c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e4a671c756d44ce80828c9cd201d6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8fa4ab3f0ac47fd875f64e0004304ec",
              "IPY_MODEL_24bf2ce5220c468f84b67fbbec6ab496",
              "IPY_MODEL_574a418cf24c42c499993e1597e1817c"
            ],
            "layout": "IPY_MODEL_a1a8f5fb8fc74a378b780279e83665f6"
          }
        },
        "b8fa4ab3f0ac47fd875f64e0004304ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a610cd40eb4d43aba9b94c743a12d747",
            "placeholder": "​",
            "style": "IPY_MODEL_c654a1cef1064ce5bb92930f23e0df2e",
            "value": "Downloading: 100%"
          }
        },
        "24bf2ce5220c468f84b67fbbec6ab496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12dcd54d4bc7444b91a591e6b0c03412",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0cfb6f20d824d0c970d32b23e2e1e47",
            "value": 48
          }
        },
        "574a418cf24c42c499993e1597e1817c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40af5014e1d44dd6919cb3ee9fa1305c",
            "placeholder": "​",
            "style": "IPY_MODEL_b8b350dcc3fb4d6188111310be6486e5",
            "value": " 48.0/48.0 [00:00&lt;00:00, 1.62kB/s]"
          }
        },
        "a1a8f5fb8fc74a378b780279e83665f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a610cd40eb4d43aba9b94c743a12d747": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c654a1cef1064ce5bb92930f23e0df2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12dcd54d4bc7444b91a591e6b0c03412": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0cfb6f20d824d0c970d32b23e2e1e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40af5014e1d44dd6919cb3ee9fa1305c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b350dcc3fb4d6188111310be6486e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b7dca9d59044bae86bbfc6ad0d93dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ca3fc4d447e4a3fa9bae61ff4c73af2",
              "IPY_MODEL_6210ee27b8da4837b38b50e04c5af293",
              "IPY_MODEL_c3356e0fb94e424aa56929a50a0961f2"
            ],
            "layout": "IPY_MODEL_3775dde66594459684248a327f97d127"
          }
        },
        "8ca3fc4d447e4a3fa9bae61ff4c73af2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d91fb1c289d41409e57c7bf0ac303f4",
            "placeholder": "​",
            "style": "IPY_MODEL_9fcda4b703994d7ab3130932ed9bc52d",
            "value": "Downloading: 100%"
          }
        },
        "6210ee27b8da4837b38b50e04c5af293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_204c8bfb58a3427bbd6834fc461c3394",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_410ff4e839b04dcd9555162987d8b562",
            "value": 570
          }
        },
        "c3356e0fb94e424aa56929a50a0961f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05e70f1aeea24fd99b3bfc0d16c1f95b",
            "placeholder": "​",
            "style": "IPY_MODEL_833ed02498804692bf3b7bb55db959be",
            "value": " 570/570 [00:00&lt;00:00, 31.0kB/s]"
          }
        },
        "3775dde66594459684248a327f97d127": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d91fb1c289d41409e57c7bf0ac303f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fcda4b703994d7ab3130932ed9bc52d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "204c8bfb58a3427bbd6834fc461c3394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "410ff4e839b04dcd9555162987d8b562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "05e70f1aeea24fd99b3bfc0d16c1f95b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "833ed02498804692bf3b7bb55db959be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "206da8bed7bd4a6b98c253ce654ce97e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06cfbd28a0c1424c86105b18945ec2d8",
              "IPY_MODEL_abbec0e5cdc1458fa94b45561f5b85e1",
              "IPY_MODEL_99d22c3afdbc4356b349ab228a348589"
            ],
            "layout": "IPY_MODEL_a3bb7390e39b4f3bb8cf5b175eaba42a"
          }
        },
        "06cfbd28a0c1424c86105b18945ec2d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a37322b047e2479ea8872211c8f179bb",
            "placeholder": "​",
            "style": "IPY_MODEL_841186a9207349d1b7def548f43fa7bf",
            "value": "Downloading: 100%"
          }
        },
        "abbec0e5cdc1458fa94b45561f5b85e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f049b6dfbee433a993e04622a5e7ce0",
            "max": 536063208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12a248a826ee408a8f4467be7a0dfa24",
            "value": 536063208
          }
        },
        "99d22c3afdbc4356b349ab228a348589": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69c678a1a6044c5d8e5efc31569cd366",
            "placeholder": "​",
            "style": "IPY_MODEL_d9d9863ec08b43fbb64b18020e64115c",
            "value": " 511M/511M [00:10&lt;00:00, 39.2MB/s]"
          }
        },
        "a3bb7390e39b4f3bb8cf5b175eaba42a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a37322b047e2479ea8872211c8f179bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "841186a9207349d1b7def548f43fa7bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f049b6dfbee433a993e04622a5e7ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12a248a826ee408a8f4467be7a0dfa24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69c678a1a6044c5d8e5efc31569cd366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9d9863ec08b43fbb64b18020e64115c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}